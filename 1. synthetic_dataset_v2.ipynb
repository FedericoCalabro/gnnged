{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Synthetic Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Definitions\n",
    "\n",
    "Following are some useful type definitions to avoid verbose code later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import networkx as nx\n",
    "from typing import Tuple\n",
    "\n",
    "# Type definitions\n",
    "Ged = int\n",
    "HistoryKey = int\n",
    "HistoryValue = Tuple[nx.Graph, Ged]\n",
    "HistoryEntry = Tuple[HistoryKey, HistoryValue]\n",
    "History = Dict[HistoryKey, HistoryValue]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomGraphGenerator\n",
    "\n",
    "RandomGraphGenerator is a class used to randomly generate graphs with some input parameters allowing for some customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from random import uniform\n",
    "from random import choice\n",
    "import networkx as nx\n",
    "\n",
    "class RandomGraphGenerator():\n",
    "    \"\"\"RandomGraphGenerator can be used to generate random graph with parameters in input.\\n\n",
    "    The way it does so ensures that there are no isolates nodes (there should be at least 2 nodes in the generated graph)\"\"\"\n",
    "    def generate_random_ER_graph(self, nmin=2, nmax=10, pmin=0.2, pmax=1):\n",
    "        \"\"\"Erdős-Rényi graph generation.\\n\n",
    "        Parameters:\n",
    "        1. nmin, min number of nodes: >= 2\n",
    "        2. nmax, max number of nodes: >= nmin\n",
    "        3. pmin, min probability for edge creation: >= 0.01\n",
    "        4. pmax, max probability for edge creation: <= 1\n",
    "        \"\"\"\n",
    "        n  = randint(nmin, nmax) # Number of nodes\n",
    "        p = uniform(pmin, pmax) # Probability for edge creation\n",
    "        G = nx.gnp_random_graph(n, p, seed=None, directed=False)\n",
    "        return self._make_connected(G)\n",
    "\n",
    "    def generate_random_BA_graph(self, nmin=2, nmax=10):\n",
    "        \"\"\"Erdős-Rényi graph generation.\\n\n",
    "        Parameters:\n",
    "        1. nmin, min number of nodes: nmin >= 2\n",
    "        2. nmax, max number of nodes: >= nmin\n",
    "        \"\"\"\n",
    "        n  = randint(nmin, nmax) # Number of nodes\n",
    "        m = randint(1, n-1) # Number of edges to attach from a new node to existing nodes,\n",
    "        if not (m >= 1 and m < n):\n",
    "            raise Exception(f\"m >= 1 and m < n\", f\"m={m}\", f\"n={n}\")\n",
    "        G = nx.barabasi_albert_graph(n, m)\n",
    "        return self._make_connected(G)\n",
    "    \n",
    "    def _make_connected(self, G : nx.Graph):\n",
    "        for node in list(nx.isolates(G)):\n",
    "            target_node = choice([n for n in G.nodes() if n != node])\n",
    "            G.add_edge(node, target_node)\n",
    "        return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consecutor Archetype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consecutor\n",
    "\n",
    "Consecutor is an abstract class which defines the prototypes to generate a graph G' starting from G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import networkx as nx\n",
    "from typing import List\n",
    "from random import randint\n",
    "from random import random\n",
    "from copy import deepcopy\n",
    "\n",
    "class UnprocessableError(Exception):\n",
    "    \"\"\"Error raised when no further process can be applied (useful in some Consecutor)\"\"\"\n",
    "    pass\n",
    "\n",
    "class Consecutor(ABC):\n",
    "    \"\"\"Abstract Consecutor with base utility methods ready for the concrete Consecutor.\n",
    "    \\nUsed to generate a Graph G' from G.\"\"\"\n",
    "    def next(self, G : nx.Graph) -> HistoryValue:\n",
    "        \"\"\"Return a tuple with a new graph G' and the distance from G (can be 0)\"\"\"\n",
    "        if not self._is_processable(G):\n",
    "            raise UnprocessableError()\n",
    "        copy = deepcopy(G)\n",
    "        rand = random()\n",
    "        return self._next(copy, rand)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _next(self, G : nx.Graph, rand : float) -> HistoryValue:\n",
    "        \"\"\"Actual next logic from concrete classes\"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def _is_processable(self, G : nx.Graph) -> bool:\n",
    "        \"\"\"Whether you can make a 'next' on graph G\"\"\"\n",
    "        return len(self._nodes(G)) > 0 and len(self._edges(G)) > 0\n",
    "    \n",
    "    def _nodes(self, G : nx.Graph) -> List[int]:\n",
    "        \"\"\"Return the list of nodes of the graph G\"\"\"\n",
    "        return list(G.nodes)\n",
    "    \n",
    "    def _edges(self, G : nx.Graph) -> List[Tuple[int, int]]:\n",
    "        \"\"\"Return the list of edges of the graph G\"\"\"\n",
    "        return list(G.edges)\n",
    "    \n",
    "    def _rand_obj_list(self, l : List):\n",
    "        \"\"\"Return a random object in list if not empty else None\"\"\"\n",
    "        return l[randint(0, len(l) - 1)] if len(l) > 0 else None\n",
    "    \n",
    "    def _new_node(self, G : nx.Graph):\n",
    "        \"\"\"Return a new node for the graph G (biggest indexed node + 1)\"\"\"\n",
    "        return (self._nodes(G)[-1] + 1) if len(self._nodes(G)) > 0 else 0\n",
    "    \n",
    "    def _rand_node(self, G : nx.Graph):\n",
    "        \"\"\"Return a random existing node of G if any else None\"\"\"\n",
    "        return self._rand_obj_list(self._nodes(G))\n",
    "    \n",
    "    def _new_edge(self, G : nx.Graph):\n",
    "        \"\"\"Return a new edgre for the graph G if not fully-connected else None\"\"\"\n",
    "        return self._rand_obj_list(list(nx.non_edges(G)))\n",
    "    \n",
    "    def _rand_edge(self, G : nx.Graph):\n",
    "        \"\"\"Return a random existing edge of G if any else None\"\"\"\n",
    "        return self._rand_obj_list(self._edges(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental Consecutor\n",
    "\n",
    "IncrementalConsecutor is a class that generates G' starting from G by adding something to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncrementalConsecutor(Consecutor):\n",
    "    \"\"\"IncrementalConsecutor add nodes and edges. The way it does so ensures there are no isolates at any moment.\"\"\"\n",
    "    def _next(self, G : nx.Graph, rand : float) -> HistoryValue:\n",
    "        if rand <= 0.33:\n",
    "            return self.__add_node_and_edges(G)\n",
    "        else:\n",
    "            return self.__add_edge(G)\n",
    "    \n",
    "    def __add_node_and_edges(self, G : nx.Graph) -> HistoryValue:\n",
    "        \"\"\"Add a new node and k edges from the new node to random nodes\"\"\"\n",
    "        new_node = super()._new_node(G)\n",
    "        G.add_node(new_node)\n",
    "        nodes = super()._nodes(G)\n",
    "        k = randint(1, len(nodes) - 1)\n",
    "        choices = list(filter(lambda n : n != new_node, nodes))\n",
    "        for _ in range(0, k):\n",
    "            target = super()._rand_obj_list(choices)\n",
    "            G.add_edge(new_node, target)\n",
    "            choices.remove(target)\n",
    "        return G, (1+k)\n",
    "            \n",
    "    def __add_edge(self, G : nx.Graph) -> HistoryValue:\n",
    "        \"\"\"Add a new edge if not fully connected\"\"\"\n",
    "        new_edge = super()._new_edge(G)\n",
    "        if new_edge is None:\n",
    "            return G, 0\n",
    "        G.add_edge(*new_edge)\n",
    "        return G, 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecrementalConsecutor\n",
    "\n",
    "DecrementalConsecutor is a class that generates G' starting from G by removing something from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecrementalConsecutor(Consecutor):\n",
    "    \"\"\"DecrementalConsecutor removes nodes and edges, after any atomic operation it also removes isolated nodes.\n",
    "    \\nThis is due to how data is stored (edge adj matrix which drops isolates informations).\"\"\"\n",
    "    def _next(self, G : nx.Graph, rand : float) -> HistoryValue:\n",
    "        if rand <= 0.33:\n",
    "            return self._remove_edge(G)\n",
    "        else:\n",
    "            return self._remove_node_and_edges(G)\n",
    "        \n",
    "    def _remove_node_and_edges(self, G : nx.Graph) -> HistoryValue:\n",
    "        \"\"\"Remove a random node along with its edges, if this causes a node to be isolated it is removed aswell\"\"\"\n",
    "        rvm_node = self._rand_node(G)\n",
    "        if rvm_node is None:\n",
    "            return G, 0\n",
    "        degree = G.degree(rvm_node)\n",
    "        G.remove_node(rvm_node)\n",
    "        isolated = list(nx.isolates(G))\n",
    "        G.remove_nodes_from(isolated)\n",
    "        return G, (1+degree+len(isolated))\n",
    "            \n",
    "    def _remove_edge(self, G : nx.Graph) -> HistoryValue:\n",
    "        \"\"\"Remove a random edge if there are any, if this causes a node to be isolated it is removed aswell\"\"\"\n",
    "        rvm_edge = self._rand_edge(G)\n",
    "        if rvm_edge is None:\n",
    "            return G, 0\n",
    "        G.remove_edge(*rvm_edge)\n",
    "        isolated = list(nx.isolates(G))\n",
    "        G.remove_nodes_from(isolated)\n",
    "        return G, (1+len(isolated))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConsecutorExecutor\n",
    "\n",
    "ConsecutorExecutor is a class that manages that execution of a concatenations of generations of new graphs by exploiting Consecutor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ConsecutorExecutor():\n",
    "    \"\"\"ConsecutorExecutor can be used to execute steps consecutions starting from a graph G\"\"\"\n",
    "    def __init__(self, consecutor: Consecutor):\n",
    "        self.consecutor = consecutor\n",
    "    \n",
    "    def execute(self, \n",
    "                G : nx.Graph, \n",
    "                steps = 100, \n",
    "                stopper : Callable[[nx.Graph], bool] = None,\n",
    "                skip_zero_ged = True,\n",
    "                ) -> History :\n",
    "        \"\"\"Perform steps attempts to modify graph G.\n",
    "        Parameters:\n",
    "        1. G, the graph where to start from\n",
    "        2. steps, the number of atomic modifications\n",
    "        3. stopper, an early custom stopping function on newly generated graph\n",
    "        4. skip_zero_ged, a Consecutor may return a G' with ged 0 w.r.t. G\n",
    "        Returns a dict representing the history of graph generations with edit distance from previous graph.\n",
    "        \"\"\"\n",
    "        history = {}\n",
    "        history[-1] = (G, 0)\n",
    "        for i in tqdm(range(0, steps), total=steps, desc=\"History Generation\"):\n",
    "            try:\n",
    "                # Generation and update G\n",
    "                G, ged = self.consecutor.next(G)\n",
    "            except UnprocessableError:\n",
    "                break\n",
    "            # Custom stopping condition on newly generated graph\n",
    "            if stopper is not None and stopper(G):\n",
    "                break\n",
    "            # Save only when necessary\n",
    "            if ged != 0 or not skip_zero_ged:\n",
    "                history[i] = (G, ged)\n",
    "        return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Functions\n",
    "\n",
    "Just two functions used together to either plot two graphs side by side or to plot a series of graphs side by side by an history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs_sbs(g1 : nx.Graph, g2 : nx.Graph):\n",
    "    \"\"\"Utility function to plot two graphs side by side\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    nx.draw(g1, with_labels=True, font_weight='bold', ax=axes[0])\n",
    "    nx.draw(g2, with_labels=True, font_weight='bold', ax=axes[1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_cons_hist_entries(history: History, stop=None):\n",
    "    \"\"\"Utility function to plot entries of history in a consecutive manner\"\"\"\n",
    "    entries = list(history.items())\n",
    "    for i,e in enumerate(entries):\n",
    "        n = entries[i+1]\n",
    "        plot_graphs_sbs(e[1][0], n[1][0])\n",
    "        if stop is not None and i+1 == stop:\n",
    "            break\n",
    "        if i+1 == len(entries) - 1:\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HistoryUtilities\n",
    "\n",
    "HistoryUtilities is a class that provides useful functions for history datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import combinations\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "class HistoryUtilities():\n",
    "    \"\"\"HistoryUtilities is responsible for providing common history utilities functions.\"\"\"\n",
    "        \n",
    "    def build_gedpickle_combination(self, history : History) -> dict:\n",
    "        \"\"\"Function that builds the ged pickle file from the combination of every pair of graphs in history\"\"\"\n",
    "        ged_dict = {}\n",
    "        # (1, 2): 10\n",
    "        entries = list(history.items())\n",
    "        all_combs = list(combinations(entries, 2))\n",
    "        for comb in tqdm(all_combs, total=len(all_combs), desc=\"Ged Dict Generation\"):\n",
    "            key = (comb[0][0], comb[1][0])\n",
    "            value = self.calculate_ged_comb(history, comb)\n",
    "            ged_dict[key] = value\n",
    "        return ged_dict\n",
    "        \n",
    "    def assert_geds(self, history : History):\n",
    "        \"\"\"Checks for every combination of history the real ged distance\"\"\"\n",
    "        all_entries = history.items()\n",
    "        all_combinations = list(combinations(all_entries, 2))\n",
    "        for comb in all_combinations:\n",
    "            g1 = comb[0][1][0]\n",
    "            g2 = comb[1][1][0]\n",
    "            r = nx.graph_edit_distance(g1, g2)\n",
    "            e = self.calculate_ged_comb(history, comb)\n",
    "            assert r == e\n",
    "            \n",
    "    def calculate_ged_comb(self, history : History, comb : Tuple[HistoryEntry, HistoryEntry]):\n",
    "        \"\"\"Returns the artificial ged distance given an entry combination\"\"\"\n",
    "        delimiters = [comb[0][0], comb[1][0]]\n",
    "        delimiters.sort()\n",
    "        min, max = delimiters[0], delimiters[1]\n",
    "        sum = 0\n",
    "        for entry in history.items():\n",
    "            key = entry[0]\n",
    "            value = entry[1]\n",
    "            if min < key <= max:\n",
    "                sum += value[1]\n",
    "            if key > max:\n",
    "                break\n",
    "        return sum\n",
    "    \n",
    "    def split_by_fractions(self, history: History, train=0.8, test=0.2):\n",
    "        \"\"\"Split history in two dicts according to proportions\"\"\"\n",
    "        assert train+test==1.0, 'fractions sum is not 1.0'\n",
    "        keys = list(history.keys())\n",
    "        shuffle(keys)\n",
    "        split_point = int(train * len(keys))\n",
    "        dict_train = {key: history[key] for key in keys[:split_point]}\n",
    "        dict_test = {key: history[key] for key in keys[split_point:]}\n",
    "        return dict_train, dict_test\n",
    "\n",
    "\n",
    "    def save_to_sparse_gexfs(self, history : History, outfolder : str):\n",
    "        \"\"\"Create/Clean outfolder than save all history as gexf files\"\"\"\n",
    "        # Create Folder if not exist\n",
    "        if not os.path.exists(outfolder):\n",
    "            os.makedirs(outfolder)\n",
    "        # Clean Folder\n",
    "        file_list = os.listdir(outfolder)\n",
    "        gefx_files = [file for file in file_list if file.endswith('.gexf')]\n",
    "        for file in gefx_files:\n",
    "            file_path = os.path.join(outfolder, file)\n",
    "            os.remove(file_path)\n",
    "        # Save to Folder\n",
    "        for key, value in tqdm(history.items(), total=len(history.items()), desc=f\"Saving to {outfolder}\"):\n",
    "            filename = os.path.join(outfolder, f'{key}.gexf')\n",
    "            nx.write_gexf(value[0], filename)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation Worflow\n",
    "\n",
    "- We start from a graph randomly generated called start\n",
    "- We define the a 'Consecutor' and 'ConsecutorExecutor'\n",
    "- We use the latter to generate an history of changes\n",
    "- We use HistoryUtilities to generate a df from the history combinations\n",
    "- We save our df to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental Dataset Generation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = RandomGraphGenerator()\n",
    "# start = generator.generate_random_ER_graph()\n",
    "\n",
    "# inc_consecutor = IncrementalConsecutor()\n",
    "# exc_consecutor = ConsecutorExecutor(inc_consecutor)\n",
    "\n",
    "# history = exc_consecutor.execute(start, steps=10)\n",
    "# hist_utils = HistoryUtilities()\n",
    "# hist_utils.assert_geds(history)\n",
    "\n",
    "# plot_cons_hist_entries(history, stop=5)\n",
    "\n",
    "# df = hist_utils.build_combinations_df(history)\n",
    "# df = df.drop_duplicates(subset=['graph_1', 'graph_2', 'labels_1', 'labels_2'])\n",
    "# df.to_json('./dataset/incremental.json', force_ascii=False, default_handler=vars, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decremental Dataset Generation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = RandomGraphGenerator()\n",
    "# start = generator.generate_random_ER_graph()\n",
    "\n",
    "# dec_consecutor = DecrementalConsecutor()\n",
    "# exc_consecutor = ConsecutorExecutor(dec_consecutor)\n",
    "\n",
    "# history = exc_consecutor.execute(start, steps=10)\n",
    "# hist_utils = HistoryUtilities()\n",
    "# hist_utils.assert_geds(history)\n",
    "\n",
    "# plot_cons_hist_entries(history, stop=5)\n",
    "\n",
    "# df = hist_utils.build_combinations_df(history)\n",
    "# df = df.drop_duplicates(subset=['graph_1', 'graph_2', 'labels_1', 'labels_2'])\n",
    "# df.to_json('./dataset/decremental.json', force_ascii=False, default_handler=vars, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse GEDs checks just to be sure\n",
    "\n",
    "Altough GEDs are asserted in the previous steps, I initially faced a problem causing the stored data not to be consistent with real GEDs.\n",
    "This was due to the fact that edge matrix are stored to the disk hence isolated nodes information was lost. Now that cannot happen anymore and the problem is solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def reverse_assert_ged(df : pd.DataFrame):\n",
    "#     g1s = df.graph_1.to_list()\n",
    "#     g2s = df.graph_2.to_list()\n",
    "#     geds = df.ged.to_list()\n",
    "\n",
    "#     for i in range(len(g1s)):\n",
    "#         G1 = nx.Graph(g1s[i])\n",
    "#         G2 = nx.Graph(g2s[i])\n",
    "#         ged = geds[i]\n",
    "#         rged = nx.graph_edit_distance(G1, G2)\n",
    "#         assert rged == ged\n",
    "\n",
    "# df_inc = pd.read_json('./dataset/incremental.json', orient='records', lines=True)\n",
    "# df_dec = pd.read_json('./dataset/decremental.json', orient='records', lines=True)\n",
    "# reverse_assert_ged(df_inc)\n",
    "# reverse_assert_ged(df_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "History Generation: 100%|██████████| 1000/1000 [00:18<00:00, 53.38it/s] \n",
      "Ged Dict Generation: 100%|██████████| 492528/492528 [00:32<00:00, 15259.05it/s]\n",
      "Saving to datasets/medium/raw/medium/train/: 100%|██████████| 844/844 [01:30<00:00,  9.36it/s]\n",
      "Saving to datasets/medium/raw/medium/test/:   1%|          | 1/149 [00:00<00:27,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set has been saved to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving to datasets/medium/raw/medium/test/: 100%|██████████| 149/149 [00:15<00:00,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set has been saved to disk\n",
      "ged.pickle file has been saved to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "generator = RandomGraphGenerator()\n",
    "hist_utils = HistoryUtilities()\n",
    "stop_on_empty = lambda G: len(list(G.nodes))==0\n",
    "\n",
    "rand = random()\n",
    "if rand <= 0.6:\n",
    "    start = generator.generate_random_ER_graph(3,10,0.3,1)\n",
    "else:\n",
    "    start = generator.generate_random_BA_graph(3,10)\n",
    "    \n",
    "rand = random()\n",
    "if rand <= 0.6:\n",
    "    consecutor = IncrementalConsecutor()\n",
    "else:\n",
    "    consecutor = DecrementalConsecutor()\n",
    "    \n",
    "exc_consecutor = ConsecutorExecutor(consecutor)\n",
    "\n",
    "# Change the parameter to generate more consecutio steps\n",
    "history = exc_consecutor.execute(start, steps=1000, stopper=stop_on_empty, skip_zero_ged=True)\n",
    "\n",
    "gedpickle = hist_utils.build_gedpickle_combination(history)\n",
    "train, test = hist_utils.split_by_fractions(history, train=0.85, test=0.15)\n",
    "\n",
    "NAME = \"medium\"\n",
    "hist_utils.save_to_sparse_gexfs(train, f'datasets/{NAME}/raw/{NAME}/train/')\n",
    "hist_utils.save_to_sparse_gexfs(test, f'datasets/{NAME}/raw/{NAME}/test/')\n",
    "pickle.dump(gedpickle, open(f'datasets/{NAME}/raw/{NAME}/ged.pickle', 'wb'))\n",
    "print(f'ged.pickle file has been saved to disk')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
