{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Synthetic Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Definitions\n",
    "\n",
    "Following are some useful type definitions to avoid verbose code later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import networkx as nx\n",
    "from typing import Tuple\n",
    "from typing import List\n",
    "\n",
    "# Type definitions\n",
    "\n",
    "# ged_value = ged_nc + ged_in + ged_ie\n",
    "# ged_nc: the number of node relabeling\n",
    "# ged_in: the number of node insertions/deletions\n",
    "# ged_ie: the number of edge insertions/deletions\n",
    "TaGED = Tuple[int, int, int, int]\n",
    "HistoryKey = int\n",
    "HistoryValue = Tuple[nx.Graph, TaGED]\n",
    "HistoryEntry = Tuple[HistoryKey, HistoryValue]\n",
    "History = Dict[HistoryKey, HistoryValue]\n",
    "#id1, id2, TaGED, mappings\n",
    "MappingGed = Tuple[int, int, int, int, int, int, List[int]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomGraphGenerator\n",
    "\n",
    "RandomGraphGenerator is a class used to randomly generate graphs with some input parameters allowing for some customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from random import uniform\n",
    "from random import choice\n",
    "import networkx as nx\n",
    "\n",
    "class RandomGraphGenerator():\n",
    "    \"\"\"RandomGraphGenerator can be used to generate random graph with parameters in input.\\n\n",
    "    The way it does so ensures that there are no isolates nodes (there should be at least 2 nodes in the generated graph)\"\"\"\n",
    "    def generate_random_ER_graph(self, nmin=2, nmax=10, pmin=0.2, pmax=1):\n",
    "        \"\"\"Erdős-Rényi graph generation.\\n\n",
    "        Parameters:\n",
    "        1. nmin, min number of nodes: >= 2\n",
    "        2. nmax, max number of nodes: >= nmin\n",
    "        3. pmin, min probability for edge creation: >= 0.01\n",
    "        4. pmax, max probability for edge creation: <= 1\n",
    "        \"\"\"\n",
    "        n  = randint(nmin, nmax) # Number of nodes\n",
    "        p = uniform(pmin, pmax) # Probability for edge creation\n",
    "        G = nx.gnp_random_graph(n, p, seed=None, directed=False)\n",
    "        return self._make_connected(G)\n",
    "\n",
    "    def generate_random_BA_graph(self, nmin=2, nmax=10):\n",
    "        \"\"\"Barabasi Albert graph generation.\\n\n",
    "        Parameters:\n",
    "        1. nmin, min number of nodes: nmin >= 2\n",
    "        2. nmax, max number of nodes: >= nmin\n",
    "        \"\"\"\n",
    "        n  = randint(nmin, nmax) # Number of nodes\n",
    "        m = randint(1, n-1) # Number of edges to attach from a new node to existing nodes,\n",
    "        if not (m >= 1 and m < n):\n",
    "            raise Exception(f\"m >= 1 and m < n\", f\"m={m}\", f\"n={n}\")\n",
    "        G = nx.barabasi_albert_graph(n, m)\n",
    "        return self._make_connected(G)\n",
    "    \n",
    "    def _make_connected(self, G : nx.Graph):\n",
    "        for node in list(nx.isolates(G)):\n",
    "            target_node = choice([n for n in G.nodes() if n != node])\n",
    "            G.add_edge(node, target_node)\n",
    "        return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consecutor Archetype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consecutor\n",
    "\n",
    "Consecutor is an abstract class which defines the prototypes to generate a graph G' starting from G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import networkx as nx\n",
    "from typing import List\n",
    "from random import randint\n",
    "from random import random\n",
    "from copy import deepcopy\n",
    "\n",
    "class UnprocessableError(Exception):\n",
    "    \"\"\"Error raised when no further process can be applied (useful in some Consecutor)\"\"\"\n",
    "    pass\n",
    "\n",
    "class Consecutor(ABC):\n",
    "    \"\"\"Abstract Consecutor with base utility methods ready for the concrete Consecutor.\n",
    "    \\nUsed to generate a Graph G' from G.\"\"\"\n",
    "    def next(self, G : nx.Graph) -> HistoryValue:\n",
    "        \"\"\"Return a tuple with a new graph G' and the distance from G (can be 0)\"\"\"\n",
    "        if not self._is_processable(G):\n",
    "            raise UnprocessableError()\n",
    "        copy = deepcopy(G)\n",
    "        rand = random()\n",
    "        return self._next(copy, rand)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _next(self, G : nx.Graph, rand : float) -> HistoryValue:\n",
    "        \"\"\"Actual next logic from concrete classes\"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def _is_processable(self, G : nx.Graph) -> bool:\n",
    "        \"\"\"Whether you can make a 'next' on graph G\"\"\"\n",
    "        return len(self._nodes(G)) > 0 and len(self._edges(G)) > 0\n",
    "    \n",
    "    def _nodes(self, G : nx.Graph) -> List[int]:\n",
    "        \"\"\"Return the list of nodes of the graph G\"\"\"\n",
    "        return list(G.nodes)\n",
    "    \n",
    "    def _edges(self, G : nx.Graph) -> List[Tuple[int, int]]:\n",
    "        \"\"\"Return the list of edges of the graph G\"\"\"\n",
    "        return list(G.edges)\n",
    "    \n",
    "    def _rand_obj_list(self, l : List):\n",
    "        \"\"\"Return a random object in list if not empty else None\"\"\"\n",
    "        return l[randint(0, len(l) - 1)] if len(l) > 0 else None\n",
    "    \n",
    "    def _new_node(self, G : nx.Graph):\n",
    "        \"\"\"Return a new node for the graph G (biggest indexed node + 1)\"\"\"\n",
    "        return (self._nodes(G)[-1] + 1) if len(self._nodes(G)) > 0 else 0\n",
    "    \n",
    "    def _rand_node(self, G : nx.Graph):\n",
    "        \"\"\"Return a random existing node of G if any else None\"\"\"\n",
    "        return self._rand_obj_list(self._nodes(G))\n",
    "    \n",
    "    def _new_edge(self, G : nx.Graph):\n",
    "        \"\"\"Return a new edgre for the graph G if not fully-connected else None\"\"\"\n",
    "        return self._rand_obj_list(list(nx.non_edges(G)))\n",
    "    \n",
    "    def _rand_edge(self, G : nx.Graph):\n",
    "        \"\"\"Return a random existing edge of G if any else None\"\"\"\n",
    "        return self._rand_obj_list(self._edges(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental Consecutor\n",
    "\n",
    "IncrementalConsecutor is a class that generates G' starting from G by adding something to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncrementalConsecutor(Consecutor):\n",
    "    \"\"\"IncrementalConsecutor add nodes and edges. The way it does so ensures there are no isolates at any moment.\"\"\"\n",
    "    def _next(self, G : nx.Graph, rand : float) -> HistoryValue:\n",
    "        if rand <= 0.7:\n",
    "            return self.__add_edge(G)\n",
    "        else:\n",
    "            return self.__add_node_and_edges(G)\n",
    "    \n",
    "    def __add_node_and_edges(self, G : nx.Graph) -> HistoryValue:\n",
    "        \"\"\"Add a new node and k edges from the new node to random nodes\"\"\"\n",
    "        new_node = super()._new_node(G)\n",
    "        G.add_node(new_node)\n",
    "        nodes = super()._nodes(G)\n",
    "        k = randint(1, len(nodes) - 1)\n",
    "        choices = list(filter(lambda n : n != new_node, nodes))\n",
    "        for _ in range(0, k):\n",
    "            target = super()._rand_obj_list(choices)\n",
    "            G.add_edge(new_node, target)\n",
    "            choices.remove(target)\n",
    "        return G, (1+k, 0, 1, k)\n",
    "            \n",
    "    def __add_edge(self, G : nx.Graph) -> HistoryValue:\n",
    "        \"\"\"Add a new edge if not fully connected\"\"\"\n",
    "        new_edge = super()._new_edge(G)\n",
    "        if new_edge is None:\n",
    "            return G, (0, 0, 0, 0)\n",
    "        G.add_edge(*new_edge)\n",
    "        return G, (1, 0, 0, 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecrementalConsecutor\n",
    "\n",
    "DecrementalConsecutor is a class that generates G' starting from G by removing something from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecrementalConsecutor(Consecutor):\n",
    "    \"\"\"DecrementalConsecutor removes nodes and edges, after any atomic operation it also removes isolated nodes.\n",
    "    \\nThis is due to how data is stored (edge adj matrix which drops isolates informations).\"\"\"\n",
    "    def _next(self, G : nx.Graph, rand : float) -> HistoryValue:\n",
    "        if rand <= 1:\n",
    "            return self._remove_edge(G)\n",
    "        else:\n",
    "            return self._remove_node_and_edges(G)\n",
    "        \n",
    "    def _remove_node_and_edges(self, G : nx.Graph) -> HistoryValue:\n",
    "        \"\"\"Remove a random node along with its edges, if this causes a node to be isolated it is removed aswell\"\"\"\n",
    "        rvm_node = self._rand_node(G)\n",
    "        if rvm_node is None:\n",
    "            return G, (0, 0, 0, 0)\n",
    "        degree = G.degree(rvm_node)\n",
    "        G.remove_node(rvm_node)\n",
    "        isolated = list(nx.isolates(G))\n",
    "        G.remove_nodes_from(isolated)\n",
    "        return G, (1+degree+len(isolated), 0, 1+len(isolated), degree)\n",
    "            \n",
    "    def _remove_edge(self, G : nx.Graph) -> HistoryValue:\n",
    "        \"\"\"Remove a random edge if there are any, if this causes a node to be isolated it is removed aswell\"\"\"\n",
    "        rvm_edge = self._rand_edge(G)\n",
    "        if rvm_edge is None:\n",
    "            return G, (0, 0, 0, 0)\n",
    "        G.remove_edge(*rvm_edge)\n",
    "        isolated = list(nx.isolates(G))\n",
    "        G.remove_nodes_from(isolated)\n",
    "        return G, (1+len(isolated), 0, len(isolated), 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConsecutorExecutor\n",
    "\n",
    "ConsecutorExecutor is a class that manages that execution of a concatenations of generations of new graphs by exploiting Consecutor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ConsecutorExecutor():\n",
    "    \"\"\"ConsecutorExecutor can be used to execute steps consecutions starting from a graph G\"\"\"\n",
    "    def __init__(self, consecutor: Consecutor):\n",
    "        self.consecutor = consecutor\n",
    "    \n",
    "    def execute(self, \n",
    "                G : nx.Graph, \n",
    "                steps = 100, \n",
    "                stopper : Callable[[nx.Graph], bool] = None,\n",
    "                skip_zero_ged = True,\n",
    "                ) -> History :\n",
    "        \"\"\"Perform steps attempts to modify graph G.\n",
    "        Parameters:\n",
    "        1. G, the graph where to start from\n",
    "        2. steps, the number of atomic modifications\n",
    "        3. stopper, an early custom stopping function on newly generated graph\n",
    "        4. skip_zero_ged, a Consecutor may return a G' with ged 0 w.r.t. G\n",
    "        Returns a dict representing the history of graph generations with edit distance from previous graph.\n",
    "        \"\"\"\n",
    "        history = {}\n",
    "        history[0] = (G, (0, 0, 0, 0))\n",
    "        for i in tqdm(range(1, steps+1), total=steps+1, desc=\"History Generation\"):\n",
    "            try:\n",
    "                # Generation and update G\n",
    "                G, taged = self.consecutor.next(G)\n",
    "            except UnprocessableError:\n",
    "                break\n",
    "            # Custom stopping condition on newly generated graph\n",
    "            if stopper is not None and stopper(G):\n",
    "                break\n",
    "            # Save only when necessary\n",
    "            if taged[0] != 0 or not skip_zero_ged:\n",
    "                history[i] = (G, taged)\n",
    "        return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Functions\n",
    "\n",
    "Just two functions used together to either plot two graphs side by side or to plot a series of graphs side by side by an history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs_sbs(g1 : nx.Graph, g2 : nx.Graph):\n",
    "    \"\"\"Utility function to plot two graphs side by side\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    nx.draw(g1, with_labels=True, font_weight='bold', ax=axes[0])\n",
    "    nx.draw(g2, with_labels=True, font_weight='bold', ax=axes[1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_cons_hist_entries(history: History, stop=None):\n",
    "    \"\"\"Utility function to plot entries of history in a consecutive manner\"\"\"\n",
    "    entries = list(history.items())\n",
    "    for i,e in enumerate(entries):\n",
    "        n = entries[i+1]\n",
    "        plot_graphs_sbs(e[1][0], n[1][0])\n",
    "        if stop is not None and i+1 == stop:\n",
    "            break\n",
    "        if i+1 == len(entries) - 1:\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HistoryUtilities\n",
    "\n",
    "HistoryUtilities is a class that provides useful functions for history datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import combinations\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "class HistoryUtilities():\n",
    "    \"\"\"HistoryUtilities is responsible for providing common history utilities functions.\"\"\"\n",
    "        \n",
    "    def build_ged_combination(self, history : History) -> List[MappingGed]:\n",
    "        \"\"\"Function that builds the ged pickle file from the combination of every pair of graphs in history\"\"\"\n",
    "        mapping_list = []\n",
    "        entries = list(history.items())\n",
    "        all_combs = list(combinations(entries, 2))\n",
    "        for comb in tqdm(all_combs, total=len(all_combs), desc=\"Ged Dict Generation\"):\n",
    "            id1, id2 = comb[0][0], comb[1][0]\n",
    "            value = self.calculate_ged_comb(history, id1, id2)\n",
    "            mapping_list.append(value)\n",
    "        return mapping_list\n",
    "    \n",
    "    def calculate_ged_comb(self, history : History, id1 : HistoryKey, id2: HistoryKey) -> MappingGed:\n",
    "        \"\"\"Returns the artificial ged distance given an entry combination\"\"\"\n",
    "        delimiters = [id1, id2]\n",
    "        delimiters.sort()\n",
    "        min, max = delimiters[0], delimiters[1]\n",
    "        ged = ged_nc = ged_in = ged_ie = 0\n",
    "        for entry in history.items():\n",
    "            key = entry[0]\n",
    "            value = entry[1]\n",
    "            if min < key <= max:\n",
    "                TaGED = value[1]\n",
    "                ged += TaGED[0]\n",
    "                ged_nc += TaGED[1]\n",
    "                ged_in += TaGED[2]\n",
    "                ged_ie += TaGED[3]\n",
    "            if key > max:\n",
    "                break\n",
    "        return (id1, id2, ged, ged_nc, ged_in, ged_ie, [])\n",
    "    \n",
    "    def split_by_fractions(self, history: History, train=0.8, test=0.2):\n",
    "        \"\"\"Split history in two dicts according to proportions\"\"\"\n",
    "        assert train+test==1.0, 'fractions sum is not 1.0'\n",
    "        keys = list(history.keys())\n",
    "        shuffle(keys)\n",
    "        split_point = int(train * len(keys))\n",
    "        dict_train = {key: history[key] for key in keys[:split_point]}\n",
    "        dict_test = {key: history[key] for key in keys[split_point:]}\n",
    "        return dict_train, dict_test\n",
    "\n",
    "\n",
    "    def save_to_sparse_jsons(self, history : History, outfolder : str):\n",
    "        \"\"\"Create/Clean outfolder than save all history as jsons files\"\"\"\n",
    "        # Create Folder if not exist\n",
    "        if not os.path.exists(outfolder):\n",
    "            os.makedirs(outfolder)\n",
    "        # Clean Folder\n",
    "        file_list = os.listdir(outfolder)\n",
    "        jsons_files = [file for file in file_list if file.endswith('.json')]\n",
    "        for file in jsons_files:\n",
    "            file_path = os.path.join(outfolder, file)\n",
    "            os.remove(file_path)\n",
    "        # Save to Folder\n",
    "        for key, value in tqdm(history.items(), total=len(history.items()), desc=f\"Saving to {outfolder}\"):\n",
    "            filename = os.path.join(outfolder, f'{key}.json')\n",
    "            with open(filename, 'w') as f:\n",
    "                graph = {}\n",
    "                graph['n'] = value[0].number_of_nodes()\n",
    "                graph['m'] = value[0].number_of_edges()\n",
    "                graph['labels'] = None\n",
    "                graph['graph'] = list(list(map(lambda t: list(t), value[0].edges)))\n",
    "                json.dump(graph, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "generator = RandomGraphGenerator()\n",
    "hist_utils = HistoryUtilities()\n",
    "stop_on_empty = lambda G: len(list(G.nodes))==0\n",
    "\n",
    "start = generator.generate_random_ER_graph(100, 100, 1, 1)\n",
    "\n",
    "# consecutor = IncrementalConsecutor()\n",
    "consecutor = DecrementalConsecutor()\n",
    "    \n",
    "exc_consecutor = ConsecutorExecutor(consecutor)\n",
    "\n",
    "# Change the parameter to generate more consecutio steps\n",
    "history = exc_consecutor.execute(start, steps=1000, stopper=stop_on_empty, skip_zero_ged=True)\n",
    "\n",
    "ged = hist_utils.build_ged_combination(history)\n",
    "train, test = hist_utils.split_by_fractions(history, train=0.8, test=0.2)\n",
    "\n",
    "NAME = \"1000g_100n\"\n",
    "hist_utils.save_to_sparse_jsons(train, f'json_data/{NAME}/train/')\n",
    "hist_utils.save_to_sparse_jsons(test, f'json_data/{NAME}/test/')\n",
    "json.dump(ged, open(f'json_data/{NAME}/TaGED.json', 'w'))\n",
    "print(f'ged file has been saved to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEVE ESSERE > 20\n",
    "\n",
    "# count = 0\n",
    "\n",
    "# for key, value in history.items():\n",
    "#     graph = value[0]\n",
    "#     if graph.number_of_nodes() <= 10:\n",
    "#         count += 1\n",
    "\n",
    "# print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
