{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class AttentionModule(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    SimGNN Attention Module to make a pass on graph.\n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        \"\"\"\n",
    "        :param args: Arguments object.\n",
    "        \"\"\"\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.args = args\n",
    "        self.setup_weights()\n",
    "        self.init_parameters()\n",
    "\n",
    "    def setup_weights(self):\n",
    "        \"\"\"\n",
    "        Defining weights.\n",
    "        \"\"\"\n",
    "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.args.filters_3, self.args.filters_3))\n",
    "\n",
    "    def init_parameters(self):\n",
    "        \"\"\"\n",
    "        Initializing weights.\n",
    "        \"\"\"\n",
    "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
    "\n",
    "    def forward(self, embedding):\n",
    "        \"\"\"\n",
    "        Making a forward propagation pass to create a graph level representation.\n",
    "        :param embedding: Result of the GCN.\n",
    "        :return representation: A graph level representation vector.\n",
    "        \"\"\"\n",
    "        global_context = torch.mean(torch.matmul(embedding, self.weight_matrix), dim=0)\n",
    "        transformed_global = torch.tanh(global_context)\n",
    "        sigmoid_scores = torch.sigmoid(torch.mm(embedding, transformed_global.view(-1, 1)))\n",
    "        representation = torch.mm(torch.t(embedding), sigmoid_scores)\n",
    "        return representation\n",
    "\n",
    "\n",
    "class TensorNetworkModule(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    SimGNN Tensor Network module to calculate similarity vector.\n",
    "    \"\"\"\n",
    "    def __init__(self, args, input_dim=None):\n",
    "        \"\"\"\n",
    "        :param args: Arguments object.\n",
    "        \"\"\"\n",
    "        super(TensorNetworkModule, self).__init__()\n",
    "        self.args = args\n",
    "        self.input_dim = self.args.filters_3 if (input_dim is None) else input_dim\n",
    "        self.setup_weights()\n",
    "        self.init_parameters()\n",
    "\n",
    "    def setup_weights(self):\n",
    "        \"\"\"\n",
    "        Defining weights.\n",
    "        \"\"\"\n",
    "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.input_dim, self.input_dim, self.args.tensor_neurons))\n",
    "\n",
    "        self.weight_matrix_block = torch.nn.Parameter(torch.Tensor(self.args.tensor_neurons, 2*self.input_dim))\n",
    "        self.bias = torch.nn.Parameter(torch.Tensor(self.args.tensor_neurons, 1))\n",
    "\n",
    "    def init_parameters(self):\n",
    "        \"\"\"\n",
    "        Initializing weights.\n",
    "        \"\"\"\n",
    "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
    "        torch.nn.init.xavier_uniform_(self.weight_matrix_block)\n",
    "        torch.nn.init.xavier_uniform_(self.bias)\n",
    "\n",
    "    def forward(self, embedding_1, embedding_2):\n",
    "        \"\"\"\n",
    "        Making a forward propagation pass to create a similarity vector.\n",
    "        :param embedding_1: Result of the 1st embedding after attention.\n",
    "        :param embedding_2: Result of the 2nd embedding after attention.\n",
    "        :return scores: A similarity score vector.\n",
    "        \"\"\"\n",
    "        scoring = torch.mm(torch.t(embedding_1), self.weight_matrix.view(self.input_dim, -1))\n",
    "        scoring = scoring.view(self.input_dim, self.args.tensor_neurons)\n",
    "        scoring = torch.mm(torch.t(scoring), embedding_2)\n",
    "        combined_representation = torch.cat((embedding_1, embedding_2))\n",
    "        block_scoring = torch.mm(self.weight_matrix_block, combined_representation)\n",
    "        scores = torch.nn.functional.relu(scoring + block_scoring + self.bias)\n",
    "        return scores\n",
    "\n",
    "\n",
    "class Mlp(torch.nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        \"\"\"\n",
    "        :param args: Arguments object.\n",
    "        :param number_of_labels: Number of node labels.\n",
    "        \"\"\"\n",
    "        super(Mlp, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        layers = []\n",
    "        '''\n",
    "        while dim > 1:\n",
    "            layers.append(torch.nn.Linear(dim, dim // 2))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "            dim = dim // 2\n",
    "        layers[-1] = torch.nn.Sigmoid()\n",
    "        '''\n",
    "\n",
    "        layers.append(torch.nn.Linear(dim, dim * 2))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Linear(dim * 2, dim))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Linear(dim, 1))\n",
    "        #layers.append(torch.nn.Sigmoid())\n",
    "\n",
    "        self.model = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(-1)\n",
    "\n",
    "\n",
    "# from noah\n",
    "class MatchingModule(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Graph-to-graph Module to gather cross-graph information.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        \"\"\"\n",
    "        :param args: Arguments object.\n",
    "        \"\"\"\n",
    "        super(MatchingModule, self).__init__()\n",
    "        self.args = args\n",
    "        self.setup_weights()\n",
    "        self.init_parameters()\n",
    "\n",
    "    def setup_weights(self):\n",
    "        \"\"\"\n",
    "        Defining weights.\n",
    "        \"\"\"\n",
    "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.args.filters_3, self.args.filters_3))\n",
    "\n",
    "    def init_parameters(self):\n",
    "        \"\"\"\n",
    "        Initializing weights.\n",
    "        \"\"\"\n",
    "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
    "\n",
    "    def forward(self, embedding):\n",
    "        \"\"\"\n",
    "        Making a forward propagation pass to create a graph level representation.\n",
    "        :param embedding: Result of the GCN/GIN.\n",
    "        :return representation: A graph level representation vector.\n",
    "        \"\"\"\n",
    "        global_context = torch.sum(torch.matmul(embedding, self.weight_matrix), dim=0)\n",
    "        transformed_global = torch.tanh(global_context)\n",
    "        return transformed_global\n",
    "\n",
    "\n",
    "#from TaGSim\n",
    "class GraphAggregationLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_features=10, out_features=10):\n",
    "        super(GraphAggregationLayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        h_prime = torch.mm(adj, input)\n",
    "        return h_prime\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'\n",
    "\n",
    "\n",
    "def sample_gumbel(shape, eps=1e-20):\n",
    "    U = torch.rand(shape)\n",
    "    return -torch.log(-torch.log(U + eps) + eps)\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature=1):\n",
    "    y = logits + sample_gumbel(logits.shape)\n",
    "    return torch.nn.functional.softmax(y / temperature, dim=-1)\n",
    "\n",
    "def gumbel_softmax(logits, temperature=1, hard=True):\n",
    "    \"\"\"\n",
    "    ST-gumple-softmax\n",
    "    input: [*, n_class]\n",
    "    return: flatten --> [*, n_class] an one-hot vector\n",
    "    \"\"\"\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "\n",
    "    if not hard:\n",
    "        return y\n",
    "\n",
    "    shape = y.shape\n",
    "    _, ind = y.max(dim=-1)\n",
    "    y_hard = torch.zeros(shape).view(-1, shape[-1])\n",
    "    y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "    y_hard = y_hard.view(*shape)\n",
    "\n",
    "    # Set gradients w.r.t. y_hard gradients w.r.t. y\n",
    "    y_hard = (y_hard - y).detach() + y\n",
    "    return y_hard\n",
    "\n",
    "'''\n",
    "def sinkhorn(a, r=1.0, num_iter=10):\n",
    "    assert len(a.shape) == 2\n",
    "    n1, n2 = a.shape\n",
    "    b = a if n1 <= n2 else a.t()\n",
    "\n",
    "    for i in range(num_iter * 2):\n",
    "        b = torch.exp(b / r)\n",
    "        b = b / b.sum(dim=0)\n",
    "        b = b.t()\n",
    "\n",
    "    return b if n1 <= n2 else b.t()\n",
    "'''\n",
    "def sinkhorn(a, r=0.1, num_iter=20):\n",
    "    assert len(a.shape) == 2\n",
    "    n1, n2 = a.shape\n",
    "    b = a if n1 <= n2 else a.t()\n",
    "\n",
    "    for i in range(num_iter * 2):\n",
    "        b = torch.exp(b / r)\n",
    "        b = b / b.sum(dim=0)\n",
    "        b = b.t()\n",
    "\n",
    "    b = (b.round() - b).detach() + b\n",
    "\n",
    "    return b if n1 <= n2 else b.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "class GedMatrixModule(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    GED matrix module.\n",
    "    d is the size of input feature;\n",
    "    k is the size of hidden layer.\n",
    "\n",
    "    Input: n1 * d, n2 * d\n",
    "    step 1 matmul: (n1 * d) matmul (k * d * d) matmul (n2 * d).t() -> k * n1 * n2\n",
    "    step 2 mlp(k, 2k, k, 1): k * n1 * n2 -> (n1n2) * k -> (n1n2) * 2k -> (n1n2) * k -> (n1n2) * 1 -> n1 * n2\n",
    "    Output: n1 * n2\n",
    "    \"\"\"\n",
    "    def __init__(self, d, k):\n",
    "        \"\"\"\n",
    "        :param args: Arguments object.\n",
    "        \"\"\"\n",
    "        super(GedMatrixModule, self).__init__()\n",
    "\n",
    "        self.d = d\n",
    "        self.k = k\n",
    "        self.init_weight_matrix()\n",
    "        self.init_mlp()\n",
    "\n",
    "    def init_weight_matrix(self):\n",
    "        \"\"\"\n",
    "        Define and initilize a weight matrix of size (k, d, d).\n",
    "        \"\"\"\n",
    "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.k, self.d, self.d))\n",
    "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
    "\n",
    "    def init_mlp(self):\n",
    "        \"\"\"\n",
    "        Define a mlp: k -> 2*k -> k -> 1\n",
    "        \"\"\"\n",
    "        k = self.k\n",
    "        layers = []\n",
    "\n",
    "        layers.append(torch.nn.Linear(k, k * 2))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Linear(k * 2, k))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Linear(k, 1))\n",
    "        # layers.append(torch.nn.Sigmoid())\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, embedding_1, embedding_2):\n",
    "        \"\"\"\n",
    "        Making a forward propagation pass to create a similar matrix.\n",
    "        :param embedding_1: GCN(graph1) of size (n1, d)\n",
    "        :param embedding_2: GCN(graph2) of size (n2, d)\n",
    "        :return result: a similar matrix of size (n1, n2)\n",
    "        \"\"\"\n",
    "        n1, d1 = embedding_1.shape\n",
    "        n2, d2 = embedding_2.shape\n",
    "        assert d1 == self.d == d2\n",
    "\n",
    "        matrix = torch.matmul(embedding_1, self.weight_matrix)\n",
    "        matrix = torch.matmul(matrix, embedding_2.t())\n",
    "        matrix = matrix.reshape(self.k, -1).t()\n",
    "        matrix = self.mlp(matrix)\n",
    "\n",
    "        return matrix.reshape(n1, n2)\n",
    "\n",
    "\n",
    "class SimpleMatrixModule(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Simple matrix module.\n",
    "    d is the size of input feature;\n",
    "    k is the size of hidden layer.\n",
    "\n",
    "    Input: n1 * d, n2 * d\n",
    "    step 1 matmul: (n1 * d) matmul (k * d * d) matmul (n2 * d).t() -> k * n1 * n2\n",
    "    step 2 mlp(k, 2k, k, 1): k * n1 * n2 -> (n1n2) * k -> (n1n2) * 2k -> (n1n2) * k -> (n1n2) * 1 -> n1 * n2\n",
    "    Output: n1 * n2\n",
    "    \"\"\"\n",
    "    def __init__(self, k):\n",
    "        \"\"\"\n",
    "        :param args: Arguments object.\n",
    "        \"\"\"\n",
    "        super(SimpleMatrixModule, self).__init__()\n",
    "\n",
    "        self.k = k\n",
    "        self.init_mlp()\n",
    "\n",
    "    def init_mlp(self):\n",
    "        \"\"\"\n",
    "        Define a mlp: k -> 2*k -> k -> 1\n",
    "        \"\"\"\n",
    "        k = self.k\n",
    "        layers = []\n",
    "\n",
    "        layers.append(torch.nn.Linear(k, k * 2))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Linear(k * 2, k))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Linear(k, 1))\n",
    "        # layers.append(torch.nn.Sigmoid())\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, embedding_1, embedding_2):\n",
    "        \"\"\"\n",
    "        Making a forward propagation pass to create a similar matrix.\n",
    "        :param embedding_1: GCN(graph1) of size (n1, d)\n",
    "        :param embedding_2: GCN(graph2) of size (n2, d)\n",
    "        :return result: a similar matrix of size (n1, n2)\n",
    "        \"\"\"\n",
    "        n1, d1 = embedding_1.shape\n",
    "        n2, d2 = embedding_2.shape\n",
    "        assert d1 == self.k == d2\n",
    "\n",
    "        tmp_1 = embedding_1.unsqueeze(1).repeat(1, n2, 1)  # n1*d -> n1 1 d -> n1 n2 d\n",
    "        tmp_2 = embedding_2.unsqueeze(0).repeat(n1, 1, 1)  # n2*d -> 1 n2 d -> n1 n2 d\n",
    "        matrix = (tmp_1.reshape([n1 * n2, -1]) * tmp_2.reshape([n1 * n2, -1])).reshape([n1 * n2, -1])\n",
    "\n",
    "        matrix = self.mlp(matrix)\n",
    "\n",
    "        return matrix.reshape(n1, n2)\n",
    "\n",
    "def fixed_mapping_loss(mapping, gt_mapping):\n",
    "    mapping_loss = torch.nn.BCEWithLogitsLoss()\n",
    "    n1, n2 = mapping.shape\n",
    "\n",
    "    epoch_percent = 0.5\n",
    "    if epoch_percent >= 1.0:\n",
    "        return mapping_loss(mapping, gt_mapping)\n",
    "\n",
    "    num_1 = gt_mapping.sum().item()\n",
    "    num_0 = n1 * n2 - num_1\n",
    "    if num_1 >= num_0: # There is no need to use mask. Directly return the complete loss.\n",
    "        return mapping_loss(mapping, gt_mapping)\n",
    "\n",
    "    p_base = num_1 / num_0\n",
    "    p = 1.0 - (p_base + epoch_percent * (1-p_base))\n",
    "\n",
    "    #p = 1.0 - (epoch_num + 1.0) / 10\n",
    "    mask = (torch.rand([n1, n2], device=gt_mapping.device) + gt_mapping) > p\n",
    "    return mapping_loss(mapping[mask], gt_mapping[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.conv import GCNConv\n",
    "\n",
    "class SimGNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    SimGNN: A Neural Network Approach to Fast Graph Similarity Computation\n",
    "    https://arxiv.org/abs/1808.05689\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args, number_of_labels):\n",
    "        \"\"\"\n",
    "        :param args: Arguments object.\n",
    "        :param number_of_labels: Number of node labels.\n",
    "        \"\"\"\n",
    "        super(SimGNN, self).__init__()\n",
    "        self.args = args\n",
    "        self.number_labels = number_of_labels\n",
    "        self.setup_layers()\n",
    "\n",
    "    def calculate_bottleneck_features(self):\n",
    "        \"\"\"\n",
    "        Deciding the shape of the bottleneck layer.\n",
    "        \"\"\"\n",
    "        if self.args.histogram:\n",
    "            self.feature_count = self.args.tensor_neurons + self.args.bins\n",
    "        else:\n",
    "            self.feature_count = self.args.tensor_neurons\n",
    "\n",
    "    def setup_layers(self):\n",
    "        \"\"\"\n",
    "        Creating the layers.\n",
    "        \"\"\"\n",
    "        self.calculate_bottleneck_features()\n",
    "        self.convolution_1 = GCNConv(self.number_labels, self.args.filters_1)\n",
    "        self.convolution_2 = GCNConv(self.args.filters_1, self.args.filters_2)\n",
    "        self.convolution_3 = GCNConv(self.args.filters_2, self.args.filters_3)\n",
    "\n",
    "        # bias\n",
    "        self.attention = AttentionModule(self.args)\n",
    "        self.tensor_network = TensorNetworkModule(self.args)\n",
    "\n",
    "        self.fully_connected_first = torch.nn.Linear(self.feature_count, self.args.bottle_neck_neurons)\n",
    "        self.fully_connected_second = torch.nn.Linear(self.args.bottle_neck_neurons, self.args.bottle_neck_neurons_2)\n",
    "        self.fully_connected_third = torch.nn.Linear(self.args.bottle_neck_neurons_2, self.args.bottle_neck_neurons_3)\n",
    "        self.scoring_layer = torch.nn.Linear(self.args.bottle_neck_neurons_3, 1)\n",
    "        # self.bias_model = torch.nn.Linear(2, 1)\n",
    "\n",
    "    def calculate_histogram(self, abstract_features_1, abstract_features_2):\n",
    "        \"\"\"\n",
    "        Calculate histogram from similarity matrix.\n",
    "        :param abstract_features_1: Feature matrix for graph 1.\n",
    "        :param abstract_features_2: Feature matrix for graph 2.\n",
    "        :return hist: Histsogram of similarity scores.\n",
    "        \"\"\"\n",
    "        scores = torch.mm(abstract_features_1, abstract_features_2).detach()\n",
    "        scores = scores.view(-1, 1)\n",
    "        hist = torch.histc(scores, bins=self.args.bins)\n",
    "        hist = hist / torch.sum(hist)\n",
    "        hist = hist.view(1, -1)\n",
    "        return hist\n",
    "\n",
    "    def convolutional_pass(self, edge_index, features):\n",
    "        \"\"\"\n",
    "        Making convolutional pass.\n",
    "        :param edge_index: Edge indices.\n",
    "        :param features: Feature matrix.\n",
    "        :return features: Abstract feature matrix.\n",
    "        \"\"\"\n",
    "        features = self.convolution_1(features, edge_index)\n",
    "        features = torch.nn.functional.relu(features)\n",
    "        features = torch.nn.functional.dropout(features, p=self.args.dropout, training=self.training)\n",
    "\n",
    "        features = self.convolution_2(features, edge_index)\n",
    "        features = torch.nn.functional.relu(features)\n",
    "        features = torch.nn.functional.dropout(features, p=self.args.dropout, training=self.training)\n",
    "\n",
    "        features = self.convolution_3(features, edge_index)\n",
    "        # features = torch.sigmoid(features)\n",
    "        return features\n",
    "\n",
    "    def ntn_pass(self, abstract_features_1, abstract_features_2):\n",
    "        pooled_features_1 = self.attention(abstract_features_1)\n",
    "        pooled_features_2 = self.attention(abstract_features_2)\n",
    "        scores = self.tensor_network(pooled_features_1, pooled_features_2)\n",
    "        scores = torch.t(scores)\n",
    "        return scores\n",
    "\n",
    "    def forward(self, data, return_ged=False):\n",
    "        \"\"\"\n",
    "        Forward pass with graphs.\n",
    "        :param data: Data dictionary.\n",
    "        :param is_testing: pass\n",
    "        :param predict_value: pass\n",
    "        :return score: Similarity score.\n",
    "        \"\"\"\n",
    "        edge_index_1 = data[\"edge_index_1\"]\n",
    "        edge_index_2 = data[\"edge_index_2\"]\n",
    "        features_1 = data[\"features_1\"]\n",
    "        features_2 = data[\"features_2\"]\n",
    "\n",
    "        abstract_features_1 = self.convolutional_pass(edge_index_1, features_1)\n",
    "        abstract_features_2 = self.convolutional_pass(edge_index_2, features_2)\n",
    "\n",
    "        scores = self.ntn_pass(abstract_features_1, abstract_features_2)\n",
    "\n",
    "        if self.args.histogram == True:\n",
    "            hist = self.calculate_histogram(abstract_features_1, torch.t(abstract_features_2))\n",
    "            scores = torch.cat((scores, hist), dim=1).view(1, -1)\n",
    "\n",
    "        scores = torch.nn.functional.relu(self.fully_connected_first(scores))\n",
    "        scores = torch.nn.functional.relu(self.fully_connected_second(scores))\n",
    "        scores = torch.nn.functional.relu(self.fully_connected_third(scores))\n",
    "        score = torch.sigmoid(self.scoring_layer(scores).view(-1))\n",
    "\n",
    "        if self.args.target_mode == \"exp\":\n",
    "            pre_ged = -torch.log(score) * data[\"avg_v\"]\n",
    "        elif self.args.target_mode == \"linear\":\n",
    "            pre_ged = score * data[\"hb\"]\n",
    "        else:\n",
    "            assert False\n",
    "        return score, pre_ged.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn.conv import GCNConv, GINConv\n",
    "\n",
    "class GPN(torch.nn.Module):\n",
    "    def __init__(self, args, number_of_labels):\n",
    "        \"\"\"\n",
    "        :param args: Arguments object.\n",
    "        :param number_of_labels: Number of node labels.\n",
    "        \"\"\"\n",
    "        super(GPN, self).__init__()\n",
    "        self.args = args\n",
    "        self.number_labels = number_of_labels\n",
    "        self.setup_layers()\n",
    "\n",
    "    def setup_layers(self):\n",
    "        \"\"\"\n",
    "        Creating the layers.\n",
    "        \"\"\"\n",
    "        self.args.gnn_operator = 'gin'\n",
    "\n",
    "        if self.args.gnn_operator == 'gcn':\n",
    "            self.convolution_1 = GCNConv(self.number_labels, self.args.filters_1)\n",
    "            self.convolution_2 = GCNConv(self.args.filters_1, self.args.filters_2)\n",
    "            self.convolution_3 = GCNConv(self.args.filters_2, self.args.filters_3)\n",
    "        elif self.args.gnn_operator == 'gin':\n",
    "            nn1 = torch.nn.Sequential(\n",
    "                torch.nn.Linear(self.number_labels, self.args.filters_1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(self.args.filters_1, self.args.filters_1),\n",
    "                torch.nn.BatchNorm1d(self.args.filters_1))\n",
    "\n",
    "            nn2 = torch.nn.Sequential(\n",
    "                torch.nn.Linear(self.args.filters_1, self.args.filters_2),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(self.args.filters_2, self.args.filters_2),\n",
    "                torch.nn.BatchNorm1d(self.args.filters_2))\n",
    "\n",
    "            nn3 = torch.nn.Sequential(\n",
    "                torch.nn.Linear(self.args.filters_2, self.args.filters_3),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(self.args.filters_3, self.args.filters_3),\n",
    "                torch.nn.BatchNorm1d(self.args.filters_3))\n",
    "\n",
    "            self.convolution_1 = GINConv(nn1, train_eps=True)\n",
    "            self.convolution_2 = GINConv(nn2, train_eps=True)\n",
    "            self.convolution_3 = GINConv(nn3, train_eps=True)\n",
    "        else:\n",
    "            raise NotImplementedError('Unknown GNN-Operator.')\n",
    "\n",
    "        self.matching_1 = MatchingModule(self.args)\n",
    "        self.matching_2 = MatchingModule(self.args)\n",
    "        self.attention = AttentionModule(self.args)\n",
    "        self.tensor_network = TensorNetworkModule(self.args)\n",
    "        self.fully_connected_first = torch.nn.Linear(self.args.tensor_neurons, self.args.bottle_neck_neurons)\n",
    "        self.scoring_layer = torch.nn.Linear(self.args.bottle_neck_neurons, 1)\n",
    "\n",
    "    def convolutional_pass(self, edge_index, features):\n",
    "        \"\"\"\n",
    "        Making convolutional pass.\n",
    "        :param edge_index: Edge indices.\n",
    "        :param features: Feature matrix.\n",
    "        :return features: Absstract feature matrix.\n",
    "        \"\"\"\n",
    "        features = self.convolution_1(features, edge_index)\n",
    "        features = torch.nn.functional.relu(features)\n",
    "        # using_dropout = self.training\n",
    "        using_dropout = False\n",
    "        features = torch.nn.functional.dropout(features, p=self.args.dropout, training=using_dropout)\n",
    "        features = self.convolution_2(features, edge_index)\n",
    "        features = torch.nn.functional.relu(features)\n",
    "        features = torch.nn.functional.dropout(features, p=self.args.dropout, training=using_dropout)\n",
    "        features = self.convolution_3(features, edge_index)\n",
    "        return features\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Forward pass with graphs.\n",
    "        :param data: Data dictionary.\n",
    "        :return score: Similarity score.\n",
    "        \"\"\"\n",
    "        edge_index_1 = data[\"edge_index_1\"]\n",
    "        edge_index_2 = data[\"edge_index_2\"]\n",
    "        features_1 = data[\"features_1\"]\n",
    "        features_2 = data[\"features_2\"]\n",
    "        abstract_features_1 = self.convolutional_pass(edge_index_1, features_1)\n",
    "        abstract_features_2 = self.convolutional_pass(edge_index_2, features_2)\n",
    "\n",
    "        tmp_feature_1 = abstract_features_1\n",
    "        tmp_feature_2 = abstract_features_2\n",
    "\n",
    "        abstract_features_1 = torch.sub(tmp_feature_1, self.matching_2(tmp_feature_2))\n",
    "        abstract_features_2 = torch.sub(tmp_feature_2, self.matching_1(tmp_feature_1))\n",
    "\n",
    "        abstract_features_1 = torch.abs(abstract_features_1)\n",
    "        abstract_features_2 = torch.abs(abstract_features_2)\n",
    "\n",
    "        pooled_features_1 = self.attention(abstract_features_1)\n",
    "        pooled_features_2 = self.attention(abstract_features_2)\n",
    "\n",
    "        scores = self.tensor_network(pooled_features_1, pooled_features_2)\n",
    "        scores = torch.t(scores)\n",
    "\n",
    "        scores = torch.nn.functional.relu(self.fully_connected_first(scores))\n",
    "        score = torch.sigmoid(self.scoring_layer(scores)).view(-1)\n",
    "        if self.args.target_mode == \"exp\":\n",
    "            pre_ged = -torch.log(score) * data[\"avg_v\"]\n",
    "        elif self.args.target_mode == \"linear\":\n",
    "            pre_ged = score * data[\"hb\"]\n",
    "        else:\n",
    "            assert False\n",
    "        return score, pre_ged.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GedGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn.conv import GCNConv, GINConv\n",
    "\n",
    "class GedGNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    SimGNN: A Neural Network Approach to Fast Graph Similarity Computation\n",
    "    https://arxiv.org/abs/1808.05689\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args, number_of_labels):\n",
    "        \"\"\"\n",
    "        :param args: Arguments object.\n",
    "        :param number_of_labels: Number of node labels.\n",
    "        \"\"\"\n",
    "        super(GedGNN, self).__init__()\n",
    "        self.args = args\n",
    "        self.number_labels = number_of_labels\n",
    "        self.setup_layers()\n",
    "\n",
    "    def setup_layers(self):\n",
    "        \"\"\"\n",
    "        Creating the layers.\n",
    "        \"\"\"\n",
    "        self.args.gnn_operator = 'gin'\n",
    "\n",
    "        if self.args.gnn_operator == 'gcn':\n",
    "            self.convolution_1 = GCNConv(self.number_labels, self.args.filters_1)\n",
    "            self.convolution_2 = GCNConv(self.args.filters_1, self.args.filters_2)\n",
    "            self.convolution_3 = GCNConv(self.args.filters_2, self.args.filters_3)\n",
    "        elif self.args.gnn_operator == 'gin':\n",
    "            nn1 = torch.nn.Sequential(\n",
    "                torch.nn.Linear(self.number_labels, self.args.filters_1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(self.args.filters_1, self.args.filters_1),\n",
    "                torch.nn.BatchNorm1d(self.args.filters_1, track_running_stats=False))\n",
    "\n",
    "            nn2 = torch.nn.Sequential(\n",
    "                torch.nn.Linear(self.args.filters_1, self.args.filters_2),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(self.args.filters_2, self.args.filters_2),\n",
    "                torch.nn.BatchNorm1d(self.args.filters_2, track_running_stats=False))\n",
    "\n",
    "            nn3 = torch.nn.Sequential(\n",
    "                torch.nn.Linear(self.args.filters_2, self.args.filters_3),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(self.args.filters_3, self.args.filters_3),\n",
    "                torch.nn.BatchNorm1d(self.args.filters_3, track_running_stats=False))\n",
    "\n",
    "            self.convolution_1 = GINConv(nn1, train_eps=True)\n",
    "            self.convolution_2 = GINConv(nn2, train_eps=True)\n",
    "            self.convolution_3 = GINConv(nn3, train_eps=True)\n",
    "        else:\n",
    "            raise NotImplementedError('Unknown GNN-Operator.')\n",
    "\n",
    "        self.mapMatrix = GedMatrixModule(self.args.filters_3, self.args.hidden_dim)\n",
    "        self.costMatrix = GedMatrixModule(self.args.filters_3, self.args.hidden_dim)\n",
    "        # self.costMatrix = SimpleMatrixModule(self.args.filters_3)\n",
    "\n",
    "        # bias\n",
    "        self.attention = AttentionModule(self.args)\n",
    "        self.tensor_network = TensorNetworkModule(self.args)\n",
    "\n",
    "        self.fully_connected_first = torch.nn.Linear(self.args.tensor_neurons, self.args.bottle_neck_neurons)\n",
    "        self.fully_connected_second = torch.nn.Linear(self.args.bottle_neck_neurons, self.args.bottle_neck_neurons_2)\n",
    "        self.fully_connected_third = torch.nn.Linear(self.args.bottle_neck_neurons_2, self.args.bottle_neck_neurons_3)\n",
    "        self.scoring_layer = torch.nn.Linear(self.args.bottle_neck_neurons_3, 1)\n",
    "        # self.bias_model = torch.nn.Linear(2, 1)\n",
    "\n",
    "    def convolutional_pass(self, edge_index, features):\n",
    "        \"\"\"\n",
    "        Making convolutional pass.\n",
    "        :param edge_index: Edge indices.\n",
    "        :param features: Feature matrix.\n",
    "        :return features: Abstract feature matrix.\n",
    "        \"\"\"\n",
    "        features = self.convolution_1(features, edge_index)\n",
    "        features = torch.nn.functional.relu(features)\n",
    "        features = torch.nn.functional.dropout(features, p=self.args.dropout, training=self.training)\n",
    "\n",
    "        features = self.convolution_2(features, edge_index)\n",
    "        features = torch.nn.functional.relu(features)\n",
    "        features = torch.nn.functional.dropout(features, p=self.args.dropout, training=self.training)\n",
    "\n",
    "        features = self.convolution_3(features, edge_index)\n",
    "        # features = torch.sigmoid(features)\n",
    "        return features\n",
    "\n",
    "    def get_bias_value(self, abstract_features_1, abstract_features_2):\n",
    "        pooled_features_1 = self.attention(abstract_features_1)\n",
    "        pooled_features_2 = self.attention(abstract_features_2)\n",
    "        scores = self.tensor_network(pooled_features_1, pooled_features_2)\n",
    "        scores = torch.t(scores)\n",
    "\n",
    "        scores = torch.nn.functional.relu(self.fully_connected_first(scores))\n",
    "        scores = torch.nn.functional.relu(self.fully_connected_second(scores))\n",
    "        scores = torch.nn.functional.relu(self.fully_connected_third(scores))\n",
    "        score = self.scoring_layer(scores).view(-1)\n",
    "        return score\n",
    "\n",
    "    @staticmethod\n",
    "    def ged_from_mapping(matrix, A1, A2, f1, f2):\n",
    "        # edge loss\n",
    "        A_loss = torch.mm(torch.mm(matrix.t(), A1), matrix) - A2\n",
    "        # label loss\n",
    "        F_loss = torch.mm(matrix.t(), f1) - f2\n",
    "        mapping_ged = ((A_loss * A_loss).sum() + (F_loss * F_loss).sum()) / 2.0\n",
    "        return mapping_ged.view(-1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Forward pass with graphs.\n",
    "        :param data: Data dictionary.\n",
    "        :param is_testing: whether return ged value together with ged score\n",
    "        :return score: Similarity score.\n",
    "        \"\"\"\n",
    "        edge_index_1 = data[\"edge_index_1\"]\n",
    "        edge_index_2 = data[\"edge_index_2\"]\n",
    "        features_1 = data[\"features_1\"]\n",
    "        features_2 = data[\"features_2\"]\n",
    "\n",
    "        abstract_features_1 = self.convolutional_pass(edge_index_1, features_1)\n",
    "        abstract_features_2 = self.convolutional_pass(edge_index_2, features_2)\n",
    "\n",
    "        cost_matrix = self.costMatrix(abstract_features_1, abstract_features_2)\n",
    "        map_matrix = self.mapMatrix(abstract_features_1, abstract_features_2)\n",
    "\n",
    "        # calculate ged using map_matrix\n",
    "        m = torch.nn.Softmax(dim=1)\n",
    "        soft_matrix = m(map_matrix) * cost_matrix\n",
    "        bias_value = self.get_bias_value(abstract_features_1, abstract_features_2)\n",
    "        score = torch.sigmoid(soft_matrix.sum() + bias_value)\n",
    "\n",
    "        if self.args.target_mode == \"exp\":\n",
    "            pre_ged = -torch.log(score) * data[\"avg_v\"]\n",
    "        elif self.args.target_mode == \"linear\":\n",
    "            pre_ged = score * data[\"hb\"]\n",
    "        else:\n",
    "            assert False\n",
    "        return score, pre_ged.item(), map_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TaGSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class TaGSim(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    TaGSim: Type-aware Graph Similarity Learning and Computation\n",
    "    https://github.com/jiyangbai/TaGSim\n",
    "    \"\"\"\n",
    "    def __init__(self, args, number_of_labels):\n",
    "        super(TaGSim, self).__init__()\n",
    "        self.args = args\n",
    "        self.number_labels = number_of_labels\n",
    "        self.setup_layers()\n",
    "\n",
    "    def setup_layers(self):\n",
    "        self.gal1 = GraphAggregationLayer()\n",
    "        self.gal2 = GraphAggregationLayer()\n",
    "        self.feature_count = self.args.tensor_neurons\n",
    "\n",
    "        self.tensor_network_nc = TensorNetworkModule(self.args, 2 * self.number_labels)\n",
    "        self.tensor_network_in = TensorNetworkModule(self.args, 2 * self.number_labels)\n",
    "        self.tensor_network_ie = TensorNetworkModule(self.args, 2 * self.number_labels)\n",
    "\n",
    "        self.fully_connected_first_nc = torch.nn.Linear(self.feature_count, self.args.bottle_neck_neurons)\n",
    "        self.fully_connected_second_nc = torch.nn.Linear(self.args.bottle_neck_neurons, 8)\n",
    "        self.fully_connected_third_nc = torch.nn.Linear(8, 4)\n",
    "        self.scoring_layer_nc = torch.nn.Linear(4, 1)\n",
    "\n",
    "        self.fully_connected_first_in = torch.nn.Linear(self.feature_count, self.args.bottle_neck_neurons)\n",
    "        self.fully_connected_second_in = torch.nn.Linear(self.args.bottle_neck_neurons, 8)\n",
    "        self.fully_connected_third_in = torch.nn.Linear(8, 4)\n",
    "        self.scoring_layer_in = torch.nn.Linear(4, 1)\n",
    "\n",
    "        self.fully_connected_first_ie = torch.nn.Linear(self.feature_count, self.args.bottle_neck_neurons)\n",
    "        self.fully_connected_second_ie = torch.nn.Linear(self.args.bottle_neck_neurons, 8)\n",
    "        self.fully_connected_third_ie = torch.nn.Linear(8, 4)\n",
    "        self.scoring_layer_ie = torch.nn.Linear(4, 1)\n",
    "\n",
    "    def gal_pass(self, edge_index, features):\n",
    "        hidden1 = self.gal1(features, edge_index)\n",
    "        hidden2 = self.gal2(hidden1, edge_index)\n",
    "\n",
    "        return hidden1, hidden2\n",
    "\n",
    "    def forward(self, data):\n",
    "        edge_index_1 = data[\"edge_index_1\"]\n",
    "        edge_index_2 = data[\"edge_index_2\"]\n",
    "        features_1 = data[\"features_1\"]\n",
    "        features_2 = data[\"features_2\"]\n",
    "        n1, n2 = data[\"n1\"], data[\"n2\"]\n",
    "\n",
    "        adj_1 = torch.sparse_coo_tensor(edge_index_1, torch.ones(edge_index_1.shape[1]), (n1, n1)).to_dense()\n",
    "        adj_2 = torch.sparse_coo_tensor(edge_index_2, torch.ones(edge_index_2.shape[1]), (n2, n2)).to_dense()\n",
    "        # remove self-loops\n",
    "        adj_1 = adj_1 * (1.0 - torch.eye(n1))\n",
    "        adj_2 = adj_2 * (1.0 - torch.eye(n2))\n",
    "\n",
    "        graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, features_1)\n",
    "        graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, features_2)\n",
    "\n",
    "        graph1_01concat = torch.cat([features_1, graph1_hidden1], dim=1)\n",
    "        graph2_01concat = torch.cat([features_2, graph2_hidden1], dim=1)\n",
    "        graph1_12concat = torch.cat([graph1_hidden1, graph1_hidden2], dim=1)\n",
    "        graph2_12concat = torch.cat([graph2_hidden1, graph2_hidden2], dim=1)\n",
    "\n",
    "        graph1_01pooled = torch.sum(graph1_01concat, dim=0).unsqueeze(1)\n",
    "        graph1_12pooled = torch.sum(graph1_12concat, dim=0).unsqueeze(1)\n",
    "        graph2_01pooled = torch.sum(graph2_01concat, dim=0).unsqueeze(1)\n",
    "        graph2_12pooled = torch.sum(graph2_12concat, dim=0).unsqueeze(1)\n",
    "\n",
    "        scores_nc = self.tensor_network_nc(graph1_01pooled, graph2_01pooled)\n",
    "        scores_nc = torch.t(scores_nc)\n",
    "\n",
    "        scores_nc = torch.nn.functional.relu(self.fully_connected_first_nc(scores_nc))\n",
    "        scores_nc = torch.nn.functional.relu(self.fully_connected_second_nc(scores_nc))\n",
    "        scores_nc = torch.nn.functional.relu(self.fully_connected_third_nc(scores_nc))\n",
    "        score_nc = torch.sigmoid(self.scoring_layer_nc(scores_nc))\n",
    "\n",
    "        scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
    "        scores_in = torch.t(scores_in)\n",
    "\n",
    "        scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
    "        scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
    "        scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
    "        score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
    "\n",
    "        scores_ie = self.tensor_network_ie(graph1_12pooled, graph2_12pooled)\n",
    "        scores_ie = torch.t(scores_ie)\n",
    "\n",
    "        scores_ie = torch.nn.functional.relu(self.fully_connected_first_ie(scores_ie))\n",
    "        scores_ie = torch.nn.functional.relu(self.fully_connected_second_ie(scores_ie))\n",
    "        scores_ie = torch.nn.functional.relu(self.fully_connected_third_ie(scores_ie))\n",
    "        score_ie = torch.sigmoid(self.scoring_layer_ie(scores_ie))\n",
    "\n",
    "        score = torch.cat([score_nc.view(-1), score_in.view(-1), score_ie.view(-1)])\n",
    "        if self.args.target_mode == \"exp\":\n",
    "            pre_ged = -torch.log(score) * data[\"avg_v\"]\n",
    "        elif self.args.target_mode == \"linear\":\n",
    "            pre_ged = score * data[\"hb\"]\n",
    "        else:\n",
    "            assert False\n",
    "        return score, pre_ged.sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename, isfile\n",
    "from os import makedirs\n",
    "from glob import glob\n",
    "import networkx as nx\n",
    "import json\n",
    "from texttable import Texttable\n",
    "\n",
    "def tab_printer(args):\n",
    "    \"\"\"\n",
    "    Function to print the logs in a nice tabular format.\n",
    "    :param args: Parameters used for the model.\n",
    "    \"\"\"\n",
    "    args = vars(args)\n",
    "    keys = sorted(args.keys())\n",
    "    t = Texttable()\n",
    "    rows = [[\"Parameter\", \"Value\"]] + [[k.replace(\"_\", \" \").capitalize(), args[k]] for k in keys]\n",
    "    t.add_rows(rows)\n",
    "    print(t.draw())\n",
    "\n",
    "def sorted_nicely(l):\n",
    "    \"\"\"\n",
    "    Sort file names in a fancy way.\n",
    "    The numbers in file names are extracted and converted from str into int first,\n",
    "    so file names can be sorted based on int comparison.\n",
    "    :param l: A list of file names:str.\n",
    "    :return: A nicely sorted file name list.\n",
    "    \"\"\"\n",
    "\n",
    "    def tryint(s):\n",
    "        try:\n",
    "            return int(s)\n",
    "        except:\n",
    "            return s\n",
    "\n",
    "    import re\n",
    "    def alphanum_key(s):\n",
    "        return [tryint(c) for c in re.split('([0-9]+)', s)]\n",
    "\n",
    "    return sorted(l, key=alphanum_key)\n",
    "\n",
    "def get_file_paths(dir, file_format='json'):\n",
    "    \"\"\"\n",
    "    Return all file paths with file_format under dir.\n",
    "    :param dir: Input path.\n",
    "    :param file_format: The suffix name of required files.\n",
    "    :return paths: The paths of all required files.\n",
    "    \"\"\"\n",
    "    dir = dir.rstrip('/')\n",
    "    paths = sorted_nicely(glob(dir + '/*.' + file_format))\n",
    "    return paths\n",
    "\n",
    "def iterate_get_graphs(dir, file_format):\n",
    "    \"\"\"\n",
    "    Read networkx (dict) graphs from all .gexf (.json) files under dir.\n",
    "    :param dir: Input path.\n",
    "    :param file_format: The suffix name of required files.\n",
    "    :return graphs: Networkx (dict) graphs.\n",
    "    \"\"\"\n",
    "    assert file_format in ['gexf', 'json', 'onehot', 'anchor']\n",
    "    graphs = []\n",
    "    for file in get_file_paths(dir, file_format):\n",
    "        gid = int(basename(file).split('.')[0])\n",
    "        if file_format == 'gexf':\n",
    "            g = nx.read_gexf(file)\n",
    "            g.graph['gid'] = gid\n",
    "            if not nx.is_connected(g):\n",
    "                raise RuntimeError('{} not connected'.format(gid))\n",
    "        elif file_format == 'json':\n",
    "            # g is a dict\n",
    "            g = json.load(open(file, 'r'))\n",
    "            g['gid'] = gid\n",
    "        elif file_format in ['onehot', 'anchor']:\n",
    "            # g is a list of onehot labels\n",
    "            g = json.load(open(file, 'r'))\n",
    "        graphs.append(g)\n",
    "    return graphs\n",
    "\n",
    "def load_all_graphs(dataset_name):\n",
    "    # graphs = iterate_get_graphs(data_location + \"json_data/\" + dataset_name + \"/train\", \"json\")\n",
    "    graphs = iterate_get_graphs(\"json_data/\" + dataset_name + \"/test\", \"json\")\n",
    "    return graphs\n",
    "\n",
    "def load_labels(dataset_name):\n",
    "    path = \"json_data/\" + dataset_name + \"/labels.json\"\n",
    "    global_labels = json.load(open(path, 'r'))\n",
    "    features = iterate_get_graphs(\"json_data/\" + dataset_name + \"/train\", \"onehot\") + iterate_get_graphs(\"json_data/\" + dataset_name + \"/test\", \"onehot\")\n",
    "    print('Load one-hot label features (dim = {}) of {}.'.format(len(global_labels), dataset_name))\n",
    "    return global_labels, features\n",
    "\n",
    "def load_ged(ged_dict, dataset_name='AIDS', file_name='TaGED.json'):\n",
    "    '''\n",
    "    list(tuple)\n",
    "    ged = [(id_1, id_2, ged_value, ged_nc, ged_in, ged_ie, [best_node_mapping])]\n",
    "\n",
    "    id_1 and id_2 are the IDs of a graph pair, e.g., the ID of 4.json is 4.\n",
    "    The given graph pairs satisfy that n1 <= n2.\n",
    "\n",
    "    ged_value = ged_nc + ged_in + ged_ie\n",
    "    (ged_nc, ged_in, ged_ie) is the type-aware ged following the setting of TaGSim.\n",
    "    ged_nc: the number of node relabeling\n",
    "    ged_in: the number of node insertions/deletions\n",
    "    ged_ie: the number of edge insertions/deletions\n",
    "\n",
    "    [best_node_mapping] contains 10 best matching at most.\n",
    "    best_node_mapping is a list of length n1: u in g1 -> best_node_mapping[u] in g2\n",
    "\n",
    "    return dict()\n",
    "    ged_dict[(id_1, id_2)] = ((ged_value, ged_nc, ged_in, ged_ie), best_node_mapping_list)\n",
    "    '''\n",
    "    path = \"json_data/{}/{}\".format(dataset_name, file_name)\n",
    "    TaGED = json.load(open(path, 'r'))\n",
    "    for (id_1, id_2, ged_value, ged_nc, ged_in, ged_ie, mappings) in TaGED:\n",
    "        ta_ged = (ged_value, ged_nc, ged_in, ged_ie)\n",
    "        ged_dict[(id_1, id_2)] = (ta_ged, mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "class Tester(object):\n",
    "    \"\"\"\n",
    "    A general model trainer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        \"\"\"\n",
    "        :param args: Arguments object.\n",
    "        \"\"\"\n",
    "        self.args = args\n",
    "        self.load_data_time = 0.0\n",
    "        self.to_torch_time = 0.0\n",
    "        self.results = []\n",
    "\n",
    "        self.use_gpu = torch.cuda.is_available()\n",
    "        self.device = torch.device('cuda') if self.use_gpu else torch.device('cpu')\n",
    "\n",
    "        self.load_data()\n",
    "        self.transfer_data_to_torch()\n",
    "        self.init_graph_pairs()\n",
    "\n",
    "        self.setup_model()\n",
    "\n",
    "    def setup_model(self):\n",
    "        if self.args.model_name == 'GPN':\n",
    "            self.model = GPN(self.args, self.number_of_labels).to(self.device)\n",
    "        elif self.args.model_name == \"SimGNN\":\n",
    "            self.args.filters_1 = 64\n",
    "            self.args.filters_2 = 32\n",
    "            self.args.filters_3 = 16\n",
    "            self.args.histogram = True\n",
    "            self.args.target_mode = 'exp'\n",
    "            self.model = SimGNN(self.args, self.number_of_labels).to(self.device)\n",
    "        elif self.args.model_name == \"GedGNN\":\n",
    "            if self.args.dataset in [\"AIDS\", \"Linux\"]:\n",
    "                self.args.loss_weight = 10.0\n",
    "            else:\n",
    "                self.args.loss_weight = 1.0\n",
    "            # self.args.target_mode = 'exp'\n",
    "            self.args.gtmap = True\n",
    "            self.model = GedGNN(self.args, self.number_of_labels).to(self.device)\n",
    "        elif self.args.model_name == \"TaGSim\":\n",
    "            self.args.target_mode = 'exp'\n",
    "            self.model = TaGSim(self.args, self.number_of_labels).to(self.device)\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load graphs, ged and labels if needed.\n",
    "        self.ged: dict-dict, ged['graph_id_1']['graph_id_2'] stores the ged value.\n",
    "        \"\"\"\n",
    "        t1 = time.time()\n",
    "        dataset_name = self.args.dataset\n",
    "        self.graphs = load_all_graphs(dataset_name)\n",
    "\n",
    "        self.number_of_labels = 0\n",
    "        if dataset_name in ['AIDS']:\n",
    "            self.global_labels, self.features = load_labels(dataset_name)\n",
    "            self.number_of_labels = len(self.global_labels)\n",
    "        if self.number_of_labels == 0:\n",
    "            self.number_of_labels = 1\n",
    "            self.features = []\n",
    "            for g in self.graphs:\n",
    "                self.features.append([[2.0] for u in range(g['n'])])\n",
    "        # print(self.global_labels)\n",
    "\n",
    "        ged_dict = dict()\n",
    "        load_ged(ged_dict, dataset_name, 'TaGED.json')\n",
    "        self.ged_dict = ged_dict\n",
    "        t2 = time.time()\n",
    "        self.load_data_time = t2 - t1\n",
    "\n",
    "    def transfer_data_to_torch(self):\n",
    "        \"\"\"\n",
    "        Transfer loaded data to torch.\n",
    "        \"\"\"\n",
    "        t1 = time.time()\n",
    "\n",
    "        self.edge_index = []\n",
    "        for g in self.graphs:\n",
    "            edge = g['graph']\n",
    "            edge = edge + [[y, x] for x, y in edge]\n",
    "            edge = edge + [[x, x] for x in range(g['n'])]\n",
    "            edge = torch.tensor(edge).t().long().to(self.device)\n",
    "            self.edge_index.append(edge)\n",
    "\n",
    "        self.features = [torch.tensor(x).float().to(self.device) for x in self.features]\n",
    "\n",
    "        n = len(self.graphs)\n",
    "        mapping = [[None for i in range(n)] for j in range(n)]\n",
    "        ged = [[(0., 0., 0., 0.) for i in range(n)] for j in range(n)]\n",
    "        gid = [g['gid'] for g in self.graphs]\n",
    "        self.gid = gid\n",
    "        self.gn = [g['n'] for g in self.graphs]\n",
    "        self.gm = [g['m'] for g in self.graphs]\n",
    "        for i in tqdm(range(n), total=n, desc=f\"transfer_data_to_torch\"):\n",
    "            mapping[i][i] = torch.eye(self.gn[i], dtype=torch.float, device=self.device)\n",
    "            for j in range(i + 1, n):\n",
    "                id_pair = (gid[i], gid[j])\n",
    "                n1, n2 = self.gn[i], self.gn[j]\n",
    "                if id_pair not in self.ged_dict:\n",
    "                    id_pair = (gid[j], gid[i])\n",
    "                    n1, n2 = n2, n1\n",
    "                if id_pair not in self.ged_dict:\n",
    "                    ged[i][j] = ged[j][i] = None\n",
    "                    mapping[i][j] = mapping[j][i] = None\n",
    "                else:\n",
    "                    ta_ged, gt_mappings = self.ged_dict[id_pair]\n",
    "                    ged[i][j] = ged[j][i] = ta_ged\n",
    "                    mapping_list = [[0 for y in range(n2)] for x in range(n1)]\n",
    "                    for gt_mapping in gt_mappings:\n",
    "                        for x, y in enumerate(gt_mapping):\n",
    "                            mapping_list[x][y] = 1\n",
    "                    mapping_matrix = torch.tensor(mapping_list).float().to(self.device)\n",
    "                    mapping[i][j] = mapping[j][i] = mapping_matrix\n",
    "        self.ged = ged\n",
    "        self.mapping = mapping\n",
    "\n",
    "        t2 = time.time()\n",
    "        self.to_torch_time = t2 - t1\n",
    "\n",
    "    def check_pair(self, i, j):\n",
    "        if i == j:\n",
    "            return (0, i, j)\n",
    "        id1, id2 = self.gid[i], self.gid[j]\n",
    "        if (id1, id2) in self.ged_dict:\n",
    "            return (0, i, j)\n",
    "        elif (id2, id1) in self.ged_dict:\n",
    "            return (0, j, i)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def init_graph_pairs(self):\n",
    "        random.seed(1)\n",
    "        self.testing_graphs = []\n",
    "        test_num = len(self.graphs)\n",
    "\n",
    "        li = [i for i in range(test_num)]\n",
    "        for i in range(test_num):\n",
    "            random.shuffle(li)\n",
    "            to_test = [j for j in range(test_num) if self.check_pair(i, j) is not None]\n",
    "            if len(to_test) >= 20:\n",
    "                #Fix to test IMDB\n",
    "                self.testing_graphs.append((0, i, to_test))\n",
    "\n",
    "        print(f\"Generated test set.\")\n",
    "\n",
    "\n",
    "\n",
    "    def pack_graph_pair(self, graph_pair):\n",
    "        \"\"\"\n",
    "        Prepare the graph pair data for GedGNN model.\n",
    "        :param graph_pair: (pair_type, id_1, id_2)\n",
    "        :return new_data: Dictionary of Torch Tensors.\n",
    "        \"\"\"\n",
    "        new_data = dict()\n",
    "\n",
    "        (pair_type, id_1, id_2) = graph_pair\n",
    "        if pair_type == 0:  # normal case\n",
    "            gid_pair = (self.gid[id_1], self.gid[id_2])\n",
    "            if gid_pair not in self.ged_dict:\n",
    "                id_1, id_2 = (id_2, id_1)\n",
    "\n",
    "            real_ged = self.ged[id_1][id_2][0]\n",
    "            ta_ged = self.ged[id_1][id_2][1:]\n",
    "\n",
    "            new_data[\"id_1\"] = id_1\n",
    "            new_data[\"id_2\"] = id_2\n",
    "\n",
    "            new_data[\"edge_index_1\"] = self.edge_index[id_1]\n",
    "            new_data[\"edge_index_2\"] = self.edge_index[id_2]\n",
    "            new_data[\"features_1\"] = self.features[id_1]\n",
    "            new_data[\"features_2\"] = self.features[id_2]\n",
    "\n",
    "            if self.args.gtmap:\n",
    "                new_data[\"mapping\"] = self.mapping[id_1][id_2]\n",
    "\n",
    "        n1, m1 = (self.gn[id_1], self.gm[id_1])\n",
    "        n2, m2 = (self.gn[id_2], self.gm[id_2])\n",
    "        new_data[\"n1\"] = n1\n",
    "        new_data[\"n2\"] = n2\n",
    "        new_data[\"ged\"] = real_ged\n",
    "        if self.args.target_mode == \"exp\":\n",
    "            avg_v = (n1 + n2) / 2.0\n",
    "            new_data[\"avg_v\"] = avg_v\n",
    "            new_data[\"target\"] = torch.exp(torch.tensor([-real_ged / avg_v]).float()).to(self.device)\n",
    "            new_data[\"ta_ged\"] = torch.exp(torch.tensor(ta_ged).float() / -avg_v).to(self.device)\n",
    "        elif self.args.target_mode == \"linear\":\n",
    "            higher_bound = max(n1, n2) + max(m1, m2)\n",
    "            new_data[\"hb\"] = higher_bound\n",
    "            new_data[\"target\"] = torch.tensor([real_ged / higher_bound]).float().to(self.device)\n",
    "            new_data[\"ta_ged\"] = (torch.tensor(ta_ged).float() / higher_bound).to(self.device)\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        return new_data\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def cal_pk(num, pre, gt):\n",
    "        tmp = list(zip(gt, pre))\n",
    "        tmp.sort()\n",
    "        beta = []\n",
    "        for i, p in enumerate(tmp):\n",
    "            beta.append((p[1], p[0], i))\n",
    "        beta.sort()\n",
    "        ans = 0\n",
    "        for i in range(num):\n",
    "            if beta[i][2] < num:\n",
    "                ans += 1\n",
    "        return ans / num\n",
    "\n",
    "    def score(self):\n",
    "        \"\"\"\n",
    "        Scoring on the test set.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.eval()\n",
    "        # self.model.train()\n",
    "\n",
    "        num = 0  # total testing number\n",
    "        time_usage = []\n",
    "        mse = []  # score mse\n",
    "        mae = []  # ged mae\n",
    "        num_acc = 0  # the number of exact prediction (pre_ged == gt_ged)\n",
    "        num_fea = 0  # the number of feasible prediction (pre_ged >= gt_ged)\n",
    "        rho = []\n",
    "        tau = []\n",
    "        pk10 = []\n",
    "        pk20 = []\n",
    "\n",
    "        for pair_type, i, j_list in tqdm(self.testing_graphs, file=sys.stdout):\n",
    "            pre = []\n",
    "            gt = []\n",
    "            t1 = time.time()\n",
    "            for j in j_list:\n",
    "                data = self.pack_graph_pair((pair_type, i, j))\n",
    "                target, gt_ged = data[\"target\"].item(), data[\"ged\"]\n",
    "                model_out = self.model(data)\n",
    "                prediction, pre_ged = model_out[0], model_out[1]\n",
    "                if pre_ged == float('inf'):\n",
    "                    pre_ged = 999\n",
    "                round_pre_ged = round(pre_ged)\n",
    "\n",
    "                num += 1\n",
    "                if prediction is None:\n",
    "                    mse.append(-0.001)\n",
    "                elif prediction.shape[0] == 1:\n",
    "                    mse.append((prediction.item() - target) ** 2)\n",
    "                else:  # TaGSim\n",
    "                    mse.append(F.mse_loss(prediction, data[\"ta_ged\"]).item())\n",
    "                pre.append(pre_ged)\n",
    "                gt.append(gt_ged)\n",
    "\n",
    "                mae.append(abs(round_pre_ged - gt_ged))\n",
    "                if round_pre_ged == gt_ged:\n",
    "                    num_acc += 1\n",
    "                    num_fea += 1\n",
    "                elif round_pre_ged > gt_ged:\n",
    "                    num_fea += 1\n",
    "            t2 = time.time()\n",
    "            time_usage.append(t2 - t1)\n",
    "            rho.append(spearmanr(pre, gt)[0])\n",
    "            tau.append(kendalltau(pre, gt)[0])\n",
    "            pk10.append(self.cal_pk(10, pre, gt))\n",
    "            pk20.append(self.cal_pk(20, pre, gt))\n",
    "\n",
    "        time_usage = round(np.mean(time_usage), 3)\n",
    "        mse = round(np.mean(mse) * 1000, 3)\n",
    "        mae = round(np.mean(mae), 3)\n",
    "        acc = round(num_acc / num, 3)\n",
    "        fea = round(num_fea / num, 3)\n",
    "        rho = round(np.mean(rho), 3)\n",
    "        tau = round(np.mean(tau), 3)\n",
    "        pk10 = round(np.mean(pk10), 3)\n",
    "        pk20 = round(np.mean(pk20), 3)\n",
    "\n",
    "        self.results.append(('model_name', 'dataset', 'graph_set', '#testing_pairs', 'time_usage(s/100p)', 'mse', 'mae', 'acc', 'fea', 'rho', 'tau', 'pk10', 'pk20'))\n",
    "        self.results.append((self.args.model_path, self.args.dataset, 'test', num, time_usage, mse, mae, acc, fea, rho, tau, pk10, pk20))\n",
    "\n",
    "        print(*self.results[-2], sep='\\t')\n",
    "        print(*self.results[-1], sep='\\t')\n",
    "        with open(self.args.result_path + 'results.txt', 'a') as f:\n",
    "            print(\"## Testing\", file=f)\n",
    "            print(\"```\", file=f)\n",
    "            print(*self.results[-2], sep='\\t', file=f)\n",
    "            print(*self.results[-1], sep='\\t', file=f)\n",
    "            print(\"```\\n\", file=f)\n",
    "\n",
    "    def load(self):\n",
    "        self.model.load_state_dict(torch.load(self.args.model_path, map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Getting params from the command line.\"\"\"\n",
    "\n",
    "import argparse\n",
    "\n",
    "def parameter_parser(args : list):\n",
    "    \"\"\"\n",
    "    A method to parse up command line parameters.\n",
    "    The default hyperparameters give a high performance model without grid search.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Run GedGNN.\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=1, help=\"Number of training epochs. Default is 1.\")\n",
    "    parser.add_argument(\"--filters-1\", type=int, default=128, help=\"Filters (neurons) in 1st convolution. Default is 64.\")\n",
    "    parser.add_argument(\"--filters-2\", type=int, default=64, help=\"Filters (neurons) in 2nd convolution. Default is 32.\")\n",
    "    parser.add_argument(\"--filters-3\", type=int, default=32, help=\"Filters (neurons) in 3rd convolution. Default is 16.\")\n",
    "    parser.add_argument(\"--tensor-neurons\", type=int, default=16, help=\"Neurons in tensor network layer. Default is 16.\")\n",
    "    parser.add_argument(\"--bottle-neck-neurons\", type=int, default=16, help=\"Bottle neck layer neurons. Default is 16.\")\n",
    "    parser.add_argument(\"--bottle-neck-neurons-2\", type=int, default=8, help=\"2nd bottle neck layer neurons. Default is 8.\")\n",
    "    parser.add_argument(\"--bottle-neck-neurons-3\", type=int, default=4, help=\"3rd bottle neck layer neurons. Default is 4.\")\n",
    "    parser.add_argument(\"--bins\", type=int, default=16, help=\"Similarity score bins. Default is 16.\")\n",
    "    parser.add_argument(\"--hidden-dim\", type=int, default=16, help=\"the size of weight matrix in GedMatrixModule. Default is 16.\")\n",
    "    parser.add_argument(\"--histogram\", dest=\"histogram\", default=False, help='Whether to use histogram.')\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=128, help=\"Number of graph pairs per batch. Default is 128.\")\n",
    "    parser.add_argument(\"--dropout\", type=float, default=0.5, help=\"Dropout probability. Default is 0.5.\")\n",
    "    parser.add_argument(\"--gtmap\", dest=\"gtmap\", action=\"store_true\", default=False, help='Whether to pack gt mapping')\n",
    "    parser.add_argument(\"--value\", dest=\"value\", action=\"store_true\", default=False, help='Predict value. Otherwise predict mapping')\n",
    "    parser.add_argument(\"--abs-path\", type=str, default=\"\", help=\"the absolute path\")\n",
    "    parser.add_argument(\"--result-path\", type=str, default='result/', help=\"Where to save the evaluation results\")\n",
    "    parser.add_argument(\"--model-path\", type=str, default='', help=\"Where to save the trained model\")\n",
    "    parser.add_argument(\"--dataset\", type=str, default='AIDS', help=\"dataset name\")\n",
    "    parser.add_argument(\"--model-name\", type=str, default='GPN', help=\"model name\")\n",
    "    parser.add_argument(\"--target-mode\", type=str, default='linear', help=\"The way of generating target, including [linear, exp].\")\n",
    "    parser.add_argument(\"--loss-weight\", type=float, default=1.0, help=\"In GedGNN, the weight of value loss. Default is 1.0.\")\n",
    "    return parser.parse_args(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args : list):\n",
    "    \"\"\"\n",
    "    Parsing command line parameters, reading data.\n",
    "    Fitting and scoring a SimGNN model.\n",
    "    \"\"\"\n",
    "    args = parameter_parser(args)\n",
    "    # tab_printer(args)\n",
    "    trainer = Tester(args)\n",
    "    trainer.load()\n",
    "    trainer.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = f\"GedGNN\"\n",
    "\n",
    "# main(args=[\n",
    "#     f\"--model-name={MODEL}\",\n",
    "#     f\"--dataset=Small\",\n",
    "#     f\"--model-path=trained_models/{MODEL}_Linux_10\"\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SimGNN trained on IMDB on test dataset IMDB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "transfer_data_to_torch: 100%|| 300/300 [00:00<00:00, 580.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated test set.\n",
      "  1%|         | 2/148 [00:02<02:44,  1.13s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m trained on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_dataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on test dataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_dataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--model-name=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--dataset=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--model-path=trained_models/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_10\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[70], line 10\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m      8\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Tester(args)\n\u001b[0;32m      9\u001b[0m trainer\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[68], line 249\u001b[0m, in \u001b[0;36mTester.score\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpack_graph_pair((pair_type, i, j))\n\u001b[0;32m    248\u001b[0m target, gt_ged \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitem(), data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mged\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 249\u001b[0m model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m prediction, pre_ged \u001b[38;5;241m=\u001b[39m model_out[\u001b[38;5;241m0\u001b[39m], model_out[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_ged \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\fedcal\\Desktop\\Fede\\gnnged\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fedcal\\Desktop\\Fede\\gnnged\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[63], line 102\u001b[0m, in \u001b[0;36mSimGNN.forward\u001b[1;34m(self, data, return_ged)\u001b[0m\n\u001b[0;32m     99\u001b[0m features_1 \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures_1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    100\u001b[0m features_2 \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures_2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 102\u001b[0m abstract_features_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolutional_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m abstract_features_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvolutional_pass(edge_index_2, features_2)\n\u001b[0;32m    105\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mntn_pass(abstract_features_1, abstract_features_2)\n",
      "Cell \u001b[1;32mIn[63], line 74\u001b[0m, in \u001b[0;36mSimGNN.convolutional_pass\u001b[1;34m(self, edge_index, features)\u001b[0m\n\u001b[0;32m     71\u001b[0m features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(features)\n\u001b[0;32m     72\u001b[0m features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(features, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m---> 74\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolution_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(features)\n\u001b[0;32m     76\u001b[0m features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(features, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\fedcal\\Desktop\\Fede\\gnnged\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fedcal\\Desktop\\Fede\\gnnged\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fedcal\\Desktop\\Fede\\gnnged\\.venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:263\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    260\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 263\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[1;32mc:\\Users\\fedcal\\Desktop\\Fede\\gnnged\\.venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:547\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    546\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[1;32m--> 547\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmsg_kwargs)\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m    549\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = [\"SimGNN\", \"GPN\", \"TaGSim\", \"GedGNN\"]\n",
    "datasets = [\"IMDB\", \"Linux\", \"1000g_100n\", \"Medium\"]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    for j, train_dataset in enumerate(datasets):\n",
    "        for k, test_dataset in enumerate(datasets):\n",
    "            print(f\"Running {model} trained on {train_dataset} on test dataset {test_dataset}, iteration {i}-{j}-{k}\")\n",
    "            main(args=[\n",
    "                f\"--model-name={model}\",\n",
    "                f\"--dataset={test_dataset}\",\n",
    "                f\"--model-path=trained_models/{model}_{train_dataset}_10\"\n",
    "            ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
