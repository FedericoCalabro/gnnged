\documentclass[../Thesis.tex]{subfiles}
\begin{document}
	\chapter{Methodology and Experimentation}
	\label{sec:methodology_and_experimentation}
	
	Working with high-quality datasets is crucial for developing performant models. However, in \cite{computing_graph_edit_distance_via_neural_graph_matching}, the data, particularly the GED labels, are mostly approximations, which negatively impacts model training and performance. A method for generating artificial data is detailed in [\autoref{sec:artificial_dataset_generation}], while the results of fair testing are summarized in the tables found in [\autoref{sec:experiments_results}]
	
	\section{Artificial Dataset Generation}
	\label{sec:artificial_dataset_generation}

	The proposed code is publicly available on \href{https://github.com/FedericoCalabro/gnnged/blob/vldb/1.%20synthetic_dataset_v2.ipynb}{GitHub} and is meant as a starting point for generating an high quality dataset composed of exact (TaGSim like) GED values along with randomly generated graphs at fixed distances.
	When working with Python programming language it is often not needed to reinvent the wheel because a package that suits requirements probably already exists and within this context, a large use of \href{https://networkx.org/}{NetworkX} (nx) is made to handle graphs data structures. Specifically, two methods for generating an artificial dataset are proposed: one does it in an incremental way, starting from a small graph and increasing its complexity with each iteration, the other does it in the opposite way, starting from a big graph and reducing its complexity at each step. With such methodology it will be possible to generate a dataset of $n$ graphs and know the GED for each pair of graph in the dataset.
	
	\subfile{../Codes/random_graph_generator}
	\textit{RandomGraphGenerator} [\autoref{code:random_graph_generator}] is a class that provides two public methods for generating random graphs by reusing \textit{nx} package. Specifically two methods for generating different variants of graphs are provided: one for \href{https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93R%C3%A9nyi_model}{Erdős-Rényi's} types of graphs (or binomial graph) and one for \href{https://en.wikipedia.org/wiki/Barab%C3%A1si%E2%80%93Albert_model}{Barabási–Albert's} ones. Additionally, it is important to make sure that graphs are connected at any time to prevent errors during future computations. 
	
	\subfile{../Codes/abstract_consecutor}
	The \textit{Consecutor} class is what will handle the generation of a graph $G'$ starting from $G$ at a fixed known GED distance. In [\autoref{code:abstract_consecutor}] is showed the abstract \textit{Consecutor} class that provides common methods for managing graphs modifications.
	
	\subfile{../Codes/incremental_consecutor}
	The \textit{IncrementalConsecutor} [\autoref{code:incremental_consecutor}] is the class responsible for creating a graph $G'$ from $G$ in an additive way. If a graph $G_1$ is at distance $d_1$ from $G_2$ and $G_3$ is generated by solely adding edges or nodes with distance $d_2$ from $G_2$ then it is demonstrable that $G_1$ is distant $|d_1 + d_2|$ from $G_3$.
	
	\subfile{../Codes/decremental_consecutor}
	At the contrary, \textit{DecrementalConsecutor} [\autoref{code:decremental_consecutor}] is the class responsible for creating a graph $G'$ from $G$ in an subtractive way. If a graph $G_1$ is at distance $d_1$ from $G_2$ and $G_3$ is generated by solely removing edges or nodes with distance $d_2$ from $G_2$ then it is demonstrable that $G_1$ is distant $|d_1 + d_2|$ from $G_3$.
	
	\subfile{../Codes/consecutor_executor}
	\textit{ConsecutorExecutor} [\autoref{code:consecutor_executor}] is the class that handles the \emph{generatio} of \emph{steps} sequential graphs by applying the \emph{next} method from either the \textit{IncrementalConsecutor} or \textit{DecrementalConsecutor}. It is not possible to apply both in the same sequence as the GED value will be invalidated between pairs of graphs: a drawback of this approach is the unfeasibility of building dense and very large datasets.
	
	\subfile{../Codes/history_utilities}
	\textit{HistoryUtilities} [\autoref{code:history_utilities}] is the final piece of utility to generate and save to disk the dataset consisting of all possible combinations of a given list of sequentially generated graphs along with their TaGED.  
	
	\subfile{../Codes/dataset_generation_example}
	With [\autoref{code:dataset_generation_example}] is an example of how to put all the pieces together to actually create a custom dataset and save it to disk in a format suitable GedGNN. With this specific code, it will be generated a dataset called \textit{Medium} (more information in \autoref{sec:experiments_results}) consisting of 1000 graphs, starting from random graph called $start$ in an \textit{incremental} way; then the data is processed to retrieve GED information for each pair of graphs and the whole is split into a training set (80\%) and a test set (20\%).
	
	\section{Experiments and Results}
	\label{sec:experiments_results}
	
	For experimenting and conducting a fair evaluation of the models, two well known datasets, \href{https://paperswithcode.com/dataset/imdb-multi}{IMDB} and \href{https://paperswithcode.com/dataset/linux}{Linux}, as well as two artificially generated datasets, \emph{1000g\_100n} and \emph{Medium} have been employed:
	
	\begin{itemize}
		\item \textbf{Linux}: A dataset that consists of graphs representing function calls within the Linux kernel: a node represent a statement and edges represent the dependency between two statements. The dataset is composed of 1000 graphs and each of them does not have more than 10 nodes, making data specialized and dense.
		\item \textbf{IMDB}: A dataset that consists of movie-related graphs: a node represents an actor, while edges connects two actors if they appear in the same movie. The dataset is composed of 1500 graphs and some of them have more than 10 nodes, making data less dense with respect to \emph{Linux}.
		\item \textbf{1000g\_100n}: An artificially generated dataset with 1000 graphs, each containing 100 nodes and a progressively less number of edges. \emph{1000g\_100n} does not represent any real scenario in particular and has been generated solely for testing purposes.
		\item \textbf{Medium}: Another artificially generated dataset with 1000 heterogeneous graphs. The variety is big, starting from 3 nodes and 3 edges in the firstly generated graph up to 297 nodes and 21457 edges in the last one, making data very sparse.
	\end{itemize}
	
	Each model presented in the VLDB paper \cite{computing_graph_edit_distance_via_neural_graph_matching}, namely SimGNN [\autoref{sec:simgnn}], GPN [\autoref{sec:gpn}], TaGSim [\autoref{sec:tagsim}] and GedGNN [\autoref{sec:gedgnn}] has been trained for 10 epochs with default parameters from the codebase as is for each of the aforementioned dataset. Then each of trained model has been tested, trying to reproduce \cite{computing_graph_edit_distance_via_neural_graph_matching} results on the respective test-set and \textbf{on all the other datasets as well} for a total of 64 combinations. In the next tables, results are presented with key metrics: 
	\begin{itemize}
		\item \textbf{Mean Squared Error (mse)}: Measures the average of the squares of the differences between the predicted GED values and real GED values.
		\item \textbf{Mean Absolute Error (mae)}: Measures the average differences between the predicted GED values and the reak GED values.
		\item \textbf{Accuracy (acc)}: Measures the proportion of correct GED predictions over the total predicted GEDs.
	\end{itemize}
	
	Since predicting GED 100\% accurately is very hard for a neural network, the most relevant metrics in this context will be the MAE and MSE.
	
	\begin{table}[H]
		\centering
		\setlength\tabcolsep{4pt}
		\renewcommand{\arraystretch}{1.2}
		\begin{tabular}{c|c|c|c|c}
			\toprule
			\textbf{trainset} & \textbf{testset} & \textbf{mse} & \textbf{mae} & \textbf{acc} \\
			\midrule
			IMDB & IMDB & 4532 & \textbf{1.28} & 0.475 \\
			IMDB & Linux & 105097 & 6506 & 0.008 \\
			IMDB & 1000g\_100n & 725792 & 327867 & 0.005 \\
			IMDB & Medium & 362746 & 5527745 & 0.004 \\ \midrule
			Linux & IMDB & 119051 & 7414 & 0.202 \\
			Linux & Linux & 2547 & \textbf{0.423} & 0.64 \\
			Linux & 1000g\_100n & 725792 & 327867 & 0.005 \\
			Linux & Medium & 390191 & 5996899 & 0.004 \\ \midrule
			1000g\_100n & IMDB & 123898 & 5104 & 0.043 \\
			1000g\_100n & Linux & 135375 & 5938 & 0.027 \\
			1000g\_100n & 1000g\_100n & 66845 & 219972 & 0.002 \\
			1000g\_100n & Medium & 40.19 & 6938538 & 0.0 \\ \midrule
			Medium & IMDB & 81696 & \textbf{5.25} & 0.057 \\
			Medium & Linux & 62777 & 5075 & 0.079 \\
			Medium & 1000g\_100n & 531549 & 314.44 & 0.002 \\
			Medium & Medium & 2436 & 2724294 & 0.001 \\
			\bottomrule
		\end{tabular}
		\caption{Results for SimGNN models}
		\label{table:simgnn}
	\end{table}
	
	As show in [\autoref{table:simgnn}], SimGNN works well if it gets trained on a specific dataset and tested on the same type of data; unfortunately there are no significant results for artificial generated datasets, but clearly the model does not generalize. \emph{SimGNN} trained on \emph{Medium} seems to show positive outcomes on \emph{IMDB} but it might due to the fact that few identical already seen graphs could have been feed to the net.
	
	\begin{table}[H]
		\centering
		\setlength\tabcolsep{4pt}
		\renewcommand{\arraystretch}{1.2}
		\begin{tabular}{c|c|c|c|c}
			\toprule
			\textbf{trainset} & \textbf{testset} & \textbf{mse} & \textbf{mae} & \textbf{acc} \\
			\midrule
			IMDB & IMDB & 106.09 & \textbf{10645} & 0.211 \\
			IMDB & Linux & 41.77 & 2762 & 0.089 \\
			IMDB & 1000g\_100n & 6936 & 327867 & 0.005 \\
			IMDB & Medium & 502857 & 7301305 & 0.005 \\ \midrule
			Linux & IMDB & 44103 & 5777 & 0.117 \\
			Linux & Linux & 57506 & \textbf{3306} & 0.065 \\
			Linux & 1000g\_100n & 101895 & 1476.37 & 0.0 \\
			Linux & Medium & 155102 & 3926197 & 0.0 \\ \midrule
			1000g\_100n & IMDB & 80138 & 8048 & 0.118 \\
			1000g\_100n & Linux & 62778 & 3251 & 0.052 \\
			1000g\_100n & 1000g\_100n & 180992 & 1979288 & 0.0 \\
			1000g\_100n & Medium & 110796 & 3312005 & 0.0 \\ \midrule
			Medium & IMDB & 85028 & 8398 & 0.061 \\
			Medium & Linux & 60467 & 3275 & 0.052 \\
			Medium & 1000g\_100n & 340701 & 2184379 & 0.0 \\
			Medium & Medium & 276667 & 5131201 & 0.001 \\
			\bottomrule
		\end{tabular}
		\caption{Results for GPN models}
		\label{table:gpn}
	\end{table}
	
	\emph{GPN} seems to be an outlier, since reproducing its original performance has not been possible. As shown in [\autoref{table:gpn}], the model does perform poorly in every associated scenario.
	
	\begin{table}[H]
		\centering
		\setlength\tabcolsep{4pt}
		\renewcommand{\arraystretch}{1.2}
		\begin{tabular}{c|c|c|c|c}
			\toprule
			\textbf{trainset} & \textbf{testset} & \textbf{mse} & \textbf{mae} & \textbf{acc} \\
			\midrule
			IMDB & IMDB & \textbf{5.2} & 2743 & 0.183 \\
			IMDB & Linux & 55426 & 6.42 & 0.006 \\
			IMDB & 1000g\_100n & 34168 & 250498 & 0.002 \\
			IMDB & Medium & 109842 & 6867463 & 0.0 \\ \midrule
			Linux & IMDB & 104002 & 185839 & 0.0 \\
			Linux & Linux & 1408 & \textbf{0.427} & 0.642 \\
			Linux & 1000g\_100n & 33935 & 671133 & 0.0 \\
			Linux & Medium & 89117 & 6445506 & 0.0 \\ \midrule
			1000g\_100n & IMDB & 179554 & 12471 & 0.001 \\
			1000g\_100n & Linux & 193506 & 16509 & 0.0 \\
			1000g\_100n & 1000g\_100n & 22926 & 225854 & 0.002 \\
			1000g\_100n & Medium & 94807 & 7074655 & 0.0 \\ \midrule
			Medium & IMDB & 101271 & 7366 & 0.155 \\
			Medium & Linux & 114007 & 11265 & 0.0 \\
			Medium & 1000g\_100n & 64129 & 671133 & 0.0 \\
			Medium & Medium & 5757 & 6446658 & 0.0 \\
			\bottomrule
		\end{tabular}
		\caption{Results for TaGSim models}
		\label{table:tagsim}
	\end{table}
	
	\emph{TaGSim} seems to show the same behaviour as \emph{SimGNN} performing good only when tested on the same type of graphs on which it got trained. A Lack of generalization capability is shown here as well.
	
	\begin{table}[H]
		\centering
		\setlength\tabcolsep{4pt}
		\renewcommand{\arraystretch}{1.2}
		\begin{tabular}{c|c|c|c|c}
			\toprule
			\textbf{trainset} & \textbf{testset} & \textbf{mse} & \textbf{mae} & \textbf{acc} \\
			\midrule
			IMDB & IMDB & 0.816 & \textbf{0.634} & 0.58 \\
			IMDB & Linux & 9399 & 1.27 & 0.221 \\
			IMDB & 1000g\_100n & 13861 & 363687 & 0.005 \\
			IMDB & Medium & 201372 & 4106777 & 0.005 \\ \midrule
			Linux & IMDB & 13153 & 3539 & 0.075 \\
			Linux & Linux & 1161 & \textbf{0.315} & 0.735 \\
			Linux & 1000g\_100n & 869809 & 4367593 & 0.0 \\
			Linux & Medium & 212754 & 3801531 & 0.0 \\ \midrule
			1000g\_100n & IMDB & 47711 & \textbf{5.86} & 0.033 \\
			1000g\_100n & Linux & 28688 & 2126 & 0.105 \\
			1000g\_100n & 1000g\_100n & 0.708 & 78892 & 0.013 \\
			1000g\_100n & Medium & 411299 & 6885001 & 0.003 \\ \midrule
			Medium & IMDB & 65417 & 7611 & 0.103 \\
			Medium & Linux & 9204 & \textbf{1.17} & 0.261 \\
			Medium & 1000g\_100n & 4651 & 259151 & 0.003 \\
			Medium & Medium & 0.718 & 267837 & 0.003 \\
			\bottomrule
		\end{tabular}
		\caption{Results for GedGNN models}
		\label{table:gedgnn}
	\end{table}	
	
	\emph{GedGNN} seems to be the most promising model for artificial dataset testing. When training on \emph{1000g\_100n} and \emph{Medium}, \emph{GedGNN} showed positive results while getting tested on both \emph{IMDB} and \emph{Linux}. A clear sign that if a much bigger and denser dataset were to be used it could have outperformed others specialized types of datasets.
	
	In conclusion, it is necessary to differentiate between the testing of models on the same data distribution that has been used during training (in-distribution) and testing on new types of data (out-of-distribution). When the models are trained and tested on similar types of graph data (in-distribution), most of the models do well with GedGNN being the best. However, when models are evaluated on data that is not part of the training distribution, the performance of all the models is rather poor. There is one exception, which is the models trained on the Medium dataset, which has the potential of enhancing the generalization but the dataset needs to be denser and much larger. At the moment, heuristic methods are usually more effective than models in out-of-distribution conditions, especially when evaluating deviation from the true GED (Graph Edit Distance).
	
\end{document}