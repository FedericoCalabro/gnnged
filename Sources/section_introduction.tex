\documentclass[../Thesis.tex]{subfiles}
\begin{document}
	\section{Introduction}
	\label{sec:introduction}
	
	Graphs are basic data structures in computer science and mathematics which are used to represent relationships between elements. It has vertices (or nodes) and edges (or links) which are the connections between any two vertices. This simple yet rich notation can model many realistic cases and therefore is a useful tool for studying many systems. For instance, social networks can be modeled as graphs where nodes are the people, and edges are the relationships between the people, which allows analyzing the social processes, the diffusion of information, and the formation of communities. All these can be analyzed using graphs in biology such as protein-protein interaction networks, neural networks of the brain and ecological networks. In the same way, in transportation, the cities can be the nodes and the roads or the flights can be the edges in a network that enables finding the best way in a city, planning of cities, and the best use of resources in terms of logistics. They can also be used to describe communication networks whereby the devices are represented as nodes and the connection as edges to help determine the flow of data, the strength of the network and the best way to allocate resources.
	
	The structures of these networks can be described by graph theory and different characteristics like connectivity, centrality, and clustering coefficient can be used to analyze the characteristics of the structures. Connectivity is the extent of the nodes’ connection, centrality determines the most influential nodes within the graph, and the clustering coefficient provides an understanding on the likelihood of the nodes to cluster. Other important properties of a graph include; graph diameter, which is defined as the maximum of the shortest path between any two nodes, and graph density which gives an idea of how connected the nodes in the graph are. These properties assist in the discovery of important information about the structure and behavior of the graph and, therefore, the analysis and decision-making process.
	
	The Graph Edit Distance (GED) problem is a key aspect in the graph theory since it gives a measure of graph similarity. GED measures the number of operations needed to transform one graph into another for example, insertions, deletions and substitutions of nodes and edges. This measure is extremely useful for a number of purposes, for example in bioinformatics where it can be used to compare the shapes of molecules in order to find new drugs or study the evolution. In computer vision, GED is important in object recognition where the structural distance between the graphical models of different objects needs to be compared in order to differentiate between them. Other graph similarity measures include graph isomorphism which compares the structural similarity of two graphs exactly and subgraph isomorphism which determines whether one graph is a sub graph of another and is used in pattern recognition and in searching for nodes and their relationships in large networks.
	
	Hence when the actual GED between two graphs is well understood it can be very meaningful. For instance, in the field of bioinformatics, the identification of the relationship between different molecular conformations can make it possible to find new drugs and target new treatments, by identifying structural features that are associated with biological activity. In the context of SNA, GED is useful in identifying nodes that form communities or clusters in a network where nodes with similar patterns of connections are grouped together and may be used in the identification of key nodes, spread of information or formation of social groups. In addition, in the application of pattern recognition and image analysis, GED can be adopted to determine the objects and relations of the structures of these objects to improve the precision and authenticity of the automatic systems. The measure of graph similarity makes it easier and more effective to compare the graphs in these areas, which in turn leads to the development of new and better solutions.
	
	However, finding the exact GED is a challenging task because of the reason that it is computationally expensive. In fact, the problem is NP-hard, and thus the time needed to find the solution increases exponentially with the size of the graphs, and becomes infeasible for large graphs. This is a brute force method, where the search for the most optimal edit path is carried out on all the possible paths and this is not feasible in real life situations. Several heuristics and approximation algorithms have been suggested, yet they suffer from the problem of achieving a reasonable compromise between the quality of the solution produced and the time taken to produce it, which affects the credibility of the results. NP-hard problems are those that are at least as difficult as the best problems in NP, and for which no efficient, fast solutions are known. This inherent difficulty serves to enhance the problem of computing GED and, therefore, the need to come up with better approximation techniques that can give good results within a short time.

	Neural networks, which are the basis of the current machine learning, are the advanced tools that are used for effective processing of numerous multi-dimensional data. A neural network is a set of models for solving a particular problem in a way that is reminiscent of the brain’s structure. It comprises a number of layers of nodes or neurons which are connected and which can take in information and produce outputs. Neural networks are fed with a lot of data which they use to fine tune the value of the various parameters that are present in their structure based on the error between the predicted output and the actual output. This training method includes forward propagation that entails feeding input data through the network to derive output and back propagation where the error is taken through the network to adjust weights in a bid to enhance precision of the model. Neural networks have been applied to a variety of problems with high success rates in image and speech recognition, natural language processing and more recently graph data analysis which has shown the flexibility of the approach.
	
	Graph Neural Networks (GNNs), are a class of Neural Networks which are designed to operate on graph data type. These architectures, called GNNs, try to take advantage of the graph structure by doing convolutions over the nodes and edges of the graph, as well as local and global properties of the graph. This makes them suitable for a number of applications such as node classification, link prediction and graph classification. Because GNNs can learn the complex patterns and representations, they can be applied for approximating the GED. GNNs work by enhancing the node representation at each step, with respect to its neighbors, thus capturing the relations and interdependencies in the graph. This is because the iterative process is useful in the learning of hierarchical representations that are essential in the understanding and analysis of graph-structured data, and thus improves the accuracy of the predictions in various applications.

	To this end, this thesis surveys the state-of-the-art methods in GED computation, including the neural network-based methods. All the works under review propose different approaches to handling the challenges of GED computation, and everyone is innovative in its way. Through the critical comparison of these methods this review seeks to determine the effectiveness as well as the weakness and opportunities that may be harnessed to enhance their effectiveness. The paper that launched the work on SimGNN \cite{simgnn__a_neural_network_approach_to_fast_graph_similarity_computation} is critical to the field, offering a strong foundation  to work on. Some of the most recent works like GedGNN \cite{computing_graph_edit_distance_via_neural_graph_matching} try to go further and offer new ideas and enhance earlier approaches.
	
	Optimization of the GED computation is very crucial especially for applications that depend on graph similarity measures. For instance, improved and more accurate GED can be used to accelerate and enhance the comparison of molecular geometries which in turn may help in the identification of new therapeutic agents. In social network analysis, it can help in the identification of more precise communities, which as a result can help in understanding the social processes and can be useful in controlling the same, thus making the interventions and policies more effective. In computer vision, the advanced techniques can improve the object recognition systems and make them more accurate and fast, which is useful in several fields such as auto-mobiles to surveillance systems. The importance of better GED computation is seen in many fields, which shows that there is still much work to be done in this area to discover new applications and improvements.
	
	In the course of this review of these articles, the aim is to present an overview of the state of the art in GED computation. Thus, focusing on the best practices and identifying directions for future studies, this thesis is intended to help develop the existing approaches to GED computation. A replication of the results of important recent works such as the work that presented GedGNN will also be performed. Furthermore, this thesis will provide constructive feedback on some issues like the quality of code and the fairness of the results, as well as the drawbacks of the datasets employed. A talk about problems such as the poor quality of the dataset and recommendation of solutions will also be given: artificial dataset creation, and the creation of neural networks that can be tested on any dataset, which will make the evaluation more equitable. This paper offers a systematic review of the methods in an attempt to identify the existing gaps and the possibilities that may lead to the development of new and better methods for use in graph theory and all its applications. It is the hope of this thesis to offer a detailed discussion and critical appraisal in order to inform future research and development work; to point the way to further improvements that will guarantee the effectiveness and applicability of GED computation methods across different disciplines.
\end{document}
